{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appletreeleaf/NLP_Projects/blob/main/LangChain%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_QA_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 여러 문서에서 찾아서 답변하는 챗봇 만들기\n",
        "\n",
        "> 유튜브 [빵형의 개발도상국](https://www.youtube.com/@bbanghyong)\n",
        "\n",
        "- QA ChatBot\n",
        "- LangChain\n",
        "- ChatGPT (gpt-3.5-turbo)\n",
        "- ChromaDB\n",
        "\n",
        "> Reference: https://youtu.be/3yPBVii7Ct0"
      ],
      "metadata": {
        "id": "LAG2G551Vx4T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 문서\n",
        "\n",
        "> TechCrunch 기사 21개"
      ],
      "metadata": {
        "id": "XJTc_m1GWTfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/kairess/toy-datasets/raw/master/techcrunch-articles.zip\n",
        "!unzip -q techcrunch-articles.zip -d articles"
      ],
      "metadata": {
        "id": "l6XPLPVrqEaV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "21개의 기사를 articles 폴더에 저장해주겠습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "0vLZ3W3D7KkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LangChain\n",
        "\n",
        "OpenAI API Key\n",
        "\n",
        "https://platform.openai.com/account/api-keys"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load multiple and process documents"
      ],
      "metadata": {
        "id": "9UcQKUId3X2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('./articles', glob=\"*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "PRSeXXc_3Ypj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5822b91-e699-4ed4-b5cc-f86b4eabbade"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "DirectoryLoader를 통해 폴더 내 모든 기사를 load해주겠습니다.\n",
        "만약 하나의 txt파일을 load할 경우 TextLoader(.txt)해주면 되겠습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "OgEF29Dm8Mgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split texts"
      ],
      "metadata": {
        "id": "L39nElP4Wdu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) # turncation\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "id": "3__nT0D4Fkmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb181cfe-23ac-49c4-eef5-96412e734da0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "chatGPT는 입력토큰 길이 제한이 있기 떄문에\n",
        "기사당 1000글자씩 split해주겠습니다.\n",
        "이때 chunk_overlap은 다음 chunk에 이전 chunk의 200자를\n",
        "overlap하겠다는 뜻입니다.\n",
        "```"
      ],
      "metadata": {
        "id": "64f5rcgU8_bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6-9jwU4ja_",
        "outputId": "e2f60f18-b7af-4c36-ee93-828b5dd9692f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='What the memo points out is that in March, a leaked foundation language model from Meta, called LLaMA, was leaked in fairly rough form. Within weeks, people tinkering around on laptops and penny-a-minute servers had added core features like instruction tuning, multiple modalities and reinforcement learning from human feedback. OpenAI and Google were probably poking around the code, too, but they didn’t — couldn’t — replicate the level of collaboration and experimentation occurring in subreddits and Discords.\\n\\nCould it really be that the titanic computation problem that seemed to pose an insurmountable obstacle — a moat — to challengers is already a relic of a different era of AI development?\\n\\nSam Altman already noted that we should expect diminishing returns when throwing parameters at the problem. Bigger isn’t always better, sure — but few would have guessed that smaller was instead.\\n\\nGPT-4 is a Walmart, and nobody actually likes Walmart', metadata={'source': 'articles/05-05-google-and-openai-are-walmarts-besieged-by-fruit-stands.txt'}),\n",
              " Document(page_content='GPT-4 is a Walmart, and nobody actually likes Walmart\\n\\nThe business paradigm being pursued by OpenAI and others right now is a direct descendant of the SaaS model. You have some software or service of high value and you offer carefully gated access to it through an API or some such. It’s a straightforward and proven approach that makes perfect sense when you’ve invested hundreds of millions into developing a single monolithic yet versatile product like a large language model.\\n\\nIf GPT-4 generalizes well to answering questions about precedents in contract law, great — never mind that a huge number of its “intellect” is dedicated to being able to parrot the style of every author who ever published a work in the English language. GPT-4 is like a Walmart. No one actually wants to go there, so the company makes damn sure there’s no other option.', metadata={'source': 'articles/05-05-google-and-openai-are-walmarts-besieged-by-fruit-stands.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Chroma DB\n",
        "\n",
        "1. Text -> Embbedings\n",
        "2. `db` 폴더에 데이터 저장\n",
        "3. DB 초기화\n",
        "4. `db` 폴더로부터 DB 로드"
      ],
      "metadata": {
        "id": "YsYsIy8F4cdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'db'\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "Q_eTIZwf4Dk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fb48d7-866b-4fa8-eaa8-8ed373244f98"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()\n",
        "vectordb = None"
      ],
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "vectordb를 비워주겠습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "ZNi7OvjEOnsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load vector db\n",
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding)"
      ],
      "metadata": {
        "id": "A-h1y_eAHmD-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a retriever"
      ],
      "metadata": {
        "id": "siLXR-XT0JoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return relevant documents about query\n",
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "# contents\n",
        "print('**contents** \\n')\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"{i+1}. {doc.page_content}\")\n",
        "    print('-'*100)\n",
        "\n",
        "# file_source\n",
        "print('**file_source** \\n')\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"{i+1}. {doc.metadata['source']}\")"
      ],
      "metadata": {
        "id": "cYA-H59u0Skn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6ea004-5cf7-4647-e30e-26d90cbea857"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**contents** \n",
            "\n",
            "1. Developers can get in on the action too, building AI steps into workflows, giving them the option of tapping into external apps and large language models to build generative AI experiences themselves. Just last week the company made its updated developer experience generally available, and this should make it easier to incorporate generative AI into the platform in customized ways, Seaman says.\n",
            "\n",
            "“So this gives us the foundation to give users choice and flexibility to bring AI into their work in their business whenever they’re ready, and however they like. We’ve got 2,600 apps in the ecosystem right now, which includes a lot of the leading LLMs, and we see a lot of customers already choosing to integrate generative AI into Slack themselves,” he said.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2. As brands incorporate generative AI into their creative workflows to generate new content associated with the company, they need to tread carefully to be sure that the new material adheres to the company’s style and brand guidelines.\n",
            "\n",
            "Nova is an early-stage startup building a suite of generative AI tools designed to protect brand integrity, and today, the company is announcing two new products to help brands police AI-generated content: BrandGuard and BrandGPT.\n",
            "\n",
            "With BrandGuard, you ingest your company’s brand guidelines and style guide, and with a series of models Nova has created, it can check the content against those rules to make sure it’s in compliance, while BrandGPT lets you ask questions about the brand’s content rules in ChatGPT style.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3. AI startup Hugging Face and ServiceNow Research, ServiceNow’s R&D division, have released StarCoder, a free alternative to code-generating AI systems along the lines of GitHub’s Copilot.\n",
            "\n",
            "Code-generating systems like DeepMind’s AlphaCode; Amazon’s CodeWhisperer; and OpenAI’s Codex, which powers Copilot, provide a tantalizing glimpse at what’s possible with AI within the realm of computer programming. Assuming the ethical, technical and legal issues are someday ironed out (and AI-powered coding tools don’t cause more bugs and security exploits than they solve), they could cut development costs substantially while allowing coders to focus on more creative tasks.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4. The legal spats between artists and the companies training AI on their artwork show no sign of abating.\n",
            "\n",
            "Within the span of a few months, several lawsuits have emerged over generative AI tech from companies including OpenAI and Stability AI, brought by plaintiffs who allege that copyrighted data — mostly art — was used without their permission to train the generative models. Generative AI models “learn” to create art, code and more by “training” on sample images and text, usually scraped indiscriminately from the web.\n",
            "\n",
            "In an effort to grant artists more control over how — and where — their art’s used, Jordan Meyer and Mathew Dryhurst co-founded the startup Spawning AI. Spawning created HaveIBeenTrained, a website that allows creators to opt out of the training dataset for one art-generating AI model, Stable Diffusion v3, due to be released in the coming months.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "**file_source** \n",
            "\n",
            "1. articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "2. articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "3. articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n",
            "4. articles/05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결과를 k개 반환"
      ],
      "metadata": {
        "id": "h3mZszDFW5aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "# k = 3\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"{i+1}. {doc.metadata['source']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58fAAOHfVLeM",
        "outputId": "161477b5-386a-485c-8842-36df9226a0be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "2. articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "3. articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a chain"
      ],
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True)"
      ],
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print('answer:')\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query"
      ],
      "metadata": {
        "id": "RjyrGZyeW_iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much money did Pando raise?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfX4vX-5RFT",
        "outputId": "448e716d-a9b1-4814-ac5d-5f274c0950e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer:\n",
            " Pando raised $30 million in a Series B round, bringing its total raised to $45 million.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "qa_chain을 선언한 후\n",
        "query를 입력해주면\n",
        "vector db에 저장된 문서를 참조해\n",
        "질문에 맞는 답변을 return 해줍니다.\n",
        "\n",
        "이어서 chin의 output을 자세히 보겠습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "kbh-uiYBRu3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response"
      ],
      "metadata": {
        "id": "olRm73t3rNt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "qa_chain의 아웃풋은\n",
        "query, result, source_document를 key로 하는 dictionary입니다.\n",
        "\n",
        "source_document는 어떤 문서를 참조했는지에 대한 정보를 나타냅니다.\n",
        "위 예시의 경우 하나의 문서만을 참조했으나,\n",
        "여러문서의 내용을 조합하는 경우도 있습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "l-6ETi_WSGX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-e6fh6rNwz",
        "outputId": "a3dab1b8-024e-4151-ad18-02ba6dbb2498"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer:\n",
            " Iron Pillar and Uncorrelated Ventures.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did Databricks acquire?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFf8D-rrN0I",
        "outputId": "c7b72893-0290-4761-c1e7-a7b96e295e90"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Databricks acquired Okera, a data governance platform with a focus on AI.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
            "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
            "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Generative AI?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5KETxphrN3d",
        "outputId": "af459e54-1843-45aa-dcdc-3e780a25d3a7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generative AI is a type of artificial intelligence that uses algorithms and data to create new and unique content, such as text, images, or code. It can be incorporated into workflows and platforms to automate and enhance creative processes, and can be customized to adhere to a brand's style and guidelines. \n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692pHNkFrN5z",
        "outputId": "c90aa23a-dfba-4f12-b5df-7ab5cdde4226"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CMA stands for Competition and Markets Authority. It is a UK government agency that is responsible for promoting competition and fair markets for consumers and businesses.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-04-cma-generative-ai-review.txt\n",
            "articles/05-04-cma-generative-ai-review.txt\n",
            "articles/05-04-cma-generative-ai-review.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "978QWCeJSRdu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
