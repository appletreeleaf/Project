{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appletreeleaf/Projects/blob/main/Project2_MRC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNKN1BYaeyyi"
      },
      "source": [
        "#Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DEbF3aJe3Zo"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdzumVuH-ZL3",
        "outputId": "d2af7a26-41fe-4bb6-ffe6-f5a1fcbaa2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.14.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.17.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRpAQhe6eW99"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import json\n",
        "from statistics import mean\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import uuid\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, AutoModel, AutoConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TdK3u3-gyI7"
      },
      "outputs": [],
      "source": [
        "for name in 'models', 'submissions':\n",
        "    os.makedirs(name, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYtIeqY-e9UO"
      },
      "source": [
        "##Set Arguments, HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8cFWD2dfFxg",
        "outputId": "40a71144-4981-416f-8524-826a3ebafa77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kobigbird_v2_ep1_max1024_lr5e-05_113\n"
          ]
        }
      ],
      "source": [
        "args = edict({'w_project': 'test_project_2_JY_02',  #goorm_project_2\n",
        "              'w_entity': 'goorm_team_1',\n",
        "              'learning_rate': 5e-5,\n",
        "              'batch_size': {'train': 128,\n",
        "                             'eval': 32,\n",
        "                             'test': 128},\n",
        "              'accumulate': 32,     # 32개씩 배치 처리\n",
        "              'epochs': 1,\n",
        "              'seed': 42,\n",
        "              'model_name': 'monologg/kobigbird-bert-base',\n",
        "              'max_length': 1024})\n",
        "\n",
        "args['NAME'] = ''f'Kobigbird_v2_ep{args.epochs}_max{args.max_length}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n",
        "print(args.NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqIMebflhc5_"
      },
      "source": [
        "#Initialize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MJAU8ExhfRO"
      },
      "source": [
        "##Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSRiSWZbhncr",
        "outputId": "d413f991-c293-4e1e-8bd8-7156b44c2bd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m02younge\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login() # API key = bcc72b6f4c340bf778bb3310374ab78fc660206e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "v_mTDCtKhoBM",
        "outputId": "d676241e-dfdc-4471-986d-ad7cc3781dde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m02younge\u001b[0m (\u001b[33mgoorm_team_1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230327_100621-gw4gv1i4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/goorm_team_1/test_project_2_JY_02/runs/gw4gv1i4' target=\"_blank\">worldly-paper-13</a></strong> to <a href='https://wandb.ai/goorm_team_1/test_project_2_JY_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/goorm_team_1/test_project_2_JY_02' target=\"_blank\">https://wandb.ai/goorm_team_1/test_project_2_JY_02</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/goorm_team_1/test_project_2_JY_02/runs/gw4gv1i4' target=\"_blank\">https://wandb.ai/goorm_team_1/test_project_2_JY_02/runs/gw4gv1i4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/goorm_team_1/test_project_2_JY_02/runs/gw4gv1i4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f86630af220>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project = args.w_project, entity = args.w_entity) # (project name, project_department)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP211vlxh86d"
      },
      "source": [
        "##Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj1h9IC5iA63"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFxsLxq6iFWf"
      },
      "source": [
        "##Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OClbVKIpiHGf"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name) # KoBigBird tokenizer = bert tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN0ji6nMiTuj"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJEM6l16iTUi",
        "outputId": "c6cdc0ae-0656-4431-ef90-53a975dff515"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdForQuestionAnswering: ['cls.predictions.decoder.bias', 'bert.pooler.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'bert.pooler.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BigBirdForQuestionAnswering were not initialized from the model checkpoint at monologg/kobigbird-bert-base and are newly initialized: ['qa_classifier.qa_outputs.bias', 'qa_classifier.intermediate.dense.weight', 'qa_classifier.intermediate.dense.bias', 'qa_classifier.output.dense.bias', 'qa_classifier.qa_outputs.weight', 'qa_classifier.output.LayerNorm.weight', 'qa_classifier.output.dense.weight', 'qa_classifier.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BigBirdForQuestionAnswering(\n",
              "  (bert): BigBirdModel(\n",
              "    (embeddings): BigBirdEmbeddings(\n",
              "      (word_embeddings): Embedding(32500, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(4096, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BigBirdEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BigBirdLayer(\n",
              "          (attention): BigBirdAttention(\n",
              "            (self): BigBirdBlockSparseAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): BigBirdSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BigBirdIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): NewGELUActivation()\n",
              "          )\n",
              "          (output): BigBirdOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_classifier): BigBirdForQuestionAnsweringHead(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (intermediate): BigBirdIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): NewGELUActivation()\n",
              "    )\n",
              "    (output): BigBirdOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(args.model_name)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZvX7IG0iZuk"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TCUtbwribuT"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHiQ1TEbjfRa"
      },
      "source": [
        "#Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpnrE8Uujhde"
      },
      "source": [
        "##Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljEclthM3og6",
        "outputId": "01294da1-15fa-460d-f8d3-e1119d720ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19HSW-SE14FB"
      },
      "outputs": [],
      "source": [
        "# context 전처리\n",
        "import re\n",
        "\n",
        "def clean_str(text):\n",
        "  pattern1 = '[一-龥]'    # 한자 제거\n",
        "  prog1 = re.compile(pattern1)\n",
        "  pattern2 = '[-=+,#/\\?:^@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]' #특수 기호\n",
        "  prog2 = re.compile(pattern2)\n",
        "  pattern3 = '\\([^\\)]+\\)' # (...) 패턴\n",
        "  prog3 = re.compile(pattern3)\n",
        "\n",
        "  result = prog1.sub(repl='', string=text)\n",
        "  result = prog2.sub(repl='', string=result)\n",
        "  result = prog3.sub(repl='', string=result)\n",
        "\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMFUFZ_FjkZw"
      },
      "outputs": [],
      "source": [
        "class KoMRC:\n",
        "    def __init__(self, data, indices: List[Tuple[int, int, int]]):\n",
        "        self._data = data\n",
        "        self._indices = indices\n",
        "\n",
        "\n",
        "    # Json을 불러오는 메소드\n",
        "    @classmethod\n",
        "    def load(cls, file_path: str):\n",
        "        with open(file_path, 'r', encoding='utf-8') as fd:\n",
        "            data = json.load(fd)\n",
        "\n",
        "        indices = []\n",
        "        for d_id, document in enumerate(data['data']):\n",
        "            for p_id, paragraph in enumerate(document['paragraphs']):\n",
        "                for q_id, _ in enumerate(paragraph['qas']):\n",
        "                    indices.append((d_id, p_id, q_id))\n",
        "\n",
        "        return cls(data, indices)\n",
        "\n",
        "    # Json을 불러오는 메소드\n",
        "    @classmethod\n",
        "        def loads(cls, *file_path: str):\n",
        "        datas = {'data': []}\n",
        "        indices = []\n",
        "\n",
        "        for f in file_path:\n",
        "            with open(f, 'r', encoding='utf-8') as fd:\n",
        "                data = json.load(fd)\n",
        "            datas['data'] += data['data']\n",
        "\n",
        "        for d_id, document in enumerate(datas['data']):\n",
        "            for p_id, paragraph in enumerate(document['paragraphs']):\n",
        "                for q_id, _ in enumerate(paragraph['qas']):\n",
        "                    indices.append((d_id, p_id, q_id))\n",
        "\n",
        "        return cls(datas, indices)\n",
        "\n",
        "    # 데이터 셋을 잘라내는 메소드\n",
        "    @classmethod\n",
        "    def split(cls, dataset, eval_ratio: float=.5):\n",
        "        indices = list(dataset._indices)\n",
        "        random.shuffle(indices)\n",
        "        train_indices = indices[int(len(indices) * eval_ratio):]\n",
        "        eval_indices = indices[:int(len(indices) * eval_ratio)]\n",
        "\n",
        "        return cls(dataset._data, train_indices), cls(dataset._data, eval_indices)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        d_id, p_id, q_id = self._indices[index]\n",
        "        paragraph = self._data['data'][d_id]['paragraphs'][p_id]\n",
        "\n",
        "        qa = paragraph['qas'][q_id]\n",
        "\n",
        "        if 'guid' in qa:\n",
        "            guid = qa['guid']\n",
        "        else:\n",
        "            guid = uuid.uuid4().hex\n",
        "\n",
        "        context = paragraph['context']\n",
        "\n",
        "        question = qa['question']\n",
        "\n",
        "        answers = qa['answers']\n",
        "        if answers != None:\n",
        "            for a in answers:\n",
        "                a['text'] = a['text'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n",
        "        else:\n",
        "            answers = None\n",
        "\n",
        "\n",
        "        return {'guid': guid,\n",
        "            'context': context,\n",
        "            'question': question,\n",
        "            'answers': answers\n",
        "        }\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n81jEe2Hq8Hw",
        "outputId": "47d16245-829e-4927-89bd-a56e9fe4dff6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255462"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_path = '/content/drive/MyDrive/Groom_8th_project2/train.json'\n",
        "train2_path = '/content/drive/MyDrive/Groom_8th_project2/train2.json'\n",
        "\n",
        "dataset = KoMRC.loads(train_path, train2_path)\n",
        "len(dataset) # 255462"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW52fxtRxowO"
      },
      "source": [
        "##Tokenize & Tag Token Positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r-mhYZ-xnrU"
      },
      "outputs": [],
      "source": [
        "class TokenizedKoMRC(KoMRC):\n",
        "    def __init__(self, data, indices: List[Tuple[int, int, int]]) -> None:\n",
        "        super().__init__(data, indices)\n",
        "        self._tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def _tokenize_with_position(self, sentence: str) -> List[Tuple[str, Tuple[int, int]]]:\n",
        "        position = 0\n",
        "        tokens = []\n",
        "\n",
        "        sentence_tokens = []\n",
        "        for word in sentence.split():\n",
        "            if '[UNK]' in tokenizer.tokenize(word):\n",
        "                sentence_tokens.append(word)\n",
        "            else:\n",
        "                sentence_tokens += tokenizer.tokenize(word)\n",
        "\n",
        "        for morph in sentence_tokens:\n",
        "            if len(morph) > 2:\n",
        "                if morph[:2] == '##':\n",
        "                    morph = morph[2:]\n",
        "\n",
        "            position = sentence.find(morph, position)\n",
        "            tokens.append((morph, (position, position + len(morph))))\n",
        "            position += len(morph)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        sample = super().__getitem__(index)\n",
        "\n",
        "        context, position = zip(*self._tokenize_with_position(sample['context']))\n",
        "        context, position = list(context), list(position)\n",
        "\n",
        "        question = self._tokenizer.tokenize(sample['question'])\n",
        "\n",
        "        if sample['answers'] is not None:\n",
        "            answers = []\n",
        "            for answer in sample['answers']:\n",
        "                for start, (position_start, position_end) in enumerate(position):\n",
        "                    if position_start <= answer['answer_start'] < position_end:\n",
        "                        break\n",
        "                else:\n",
        "                    print(context, answer)\n",
        "                    print(answer['guid'])\n",
        "                    print(answer['answer_start'])\n",
        "                    raise ValueError(\"No mathced start position\")\n",
        "\n",
        "                target = ''.join(answer['text'].split(' '))\n",
        "                source = ''\n",
        "                for end, morph in enumerate(context[start:], start):\n",
        "                    source += morph\n",
        "                    if target in source:\n",
        "                        break\n",
        "                else:\n",
        "                    print(context, answer)\n",
        "                    print(answer['guid'])\n",
        "                    print(answer['answer_start'])\n",
        "                    raise ValueError(\"No Matched end position\")\n",
        "\n",
        "                answers.append({\n",
        "                    'start': start,\n",
        "                    'end': end\n",
        "                  })\n",
        "            answer_text = sample['answers'][0]['text']\n",
        "\n",
        "        else:\n",
        "            answers = None\n",
        "            answer_text = None\n",
        "\n",
        "        return {\n",
        "            'guid': sample['guid'],\n",
        "            'context_original': clean_str(sample['context']),\n",
        "            'context_position': position,\n",
        "            'question_original': sample['question'],\n",
        "            'context': context,\n",
        "            'question': question,\n",
        "            'answers': answers,\n",
        "            'answers_text': answer_text\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePZrW88JC-HS",
        "outputId": "8aef5bf2-24d0-4910-ec2a-b658aefe4be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Train Samples: 114958\n",
            "Number of Dev Samples: 12773\n"
          ]
        }
      ],
      "source": [
        "dataset = TokenizedKoMRC.loads(train_path, train2_path)\n",
        "dataset_, remain = TokenizedKoMRC.split(dataset) # 5:5 절반만 남기기\n",
        "train_dataset, dev_dataset = TokenizedKoMRC.split(dataset_, eval_ratio=0.1)\n",
        "\n",
        "\n",
        "print(\"Number of Train Samples:\", len(train_dataset))\n",
        "print(\"Number of Dev Samples:\", len(dev_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycCFPcHsM5rB"
      },
      "source": [
        "##input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-WHKiZaGE9T"
      },
      "outputs": [],
      "source": [
        "class Indexer:\n",
        "    def __init__(self, vocabs: List[str], max_length: int=args.max_length):\n",
        "        self.max_length = max_length\n",
        "        self.vocabs = vocabs\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocabs)\n",
        "    @property\n",
        "    def pad_id(self):\n",
        "        return tokenizer.vocab['[PAD]']\n",
        "    @property\n",
        "    def unk_id(self):\n",
        "        return tokenizer.vocab['[UNK]']\n",
        "    @property\n",
        "    def cls_id(self):\n",
        "        return tokenizer.vocab['[CLS]']\n",
        "    @property\n",
        "    def sep_id(self):\n",
        "        return tokenizer.vocab['[SEP]']\n",
        "\n",
        "\n",
        "    def sample2ids(self, sample: Dict[str, Any],) -> Dict[str, Any]:\n",
        "        context = [tokenizer.convert_tokens_to_ids(token) for token in sample['context']]\n",
        "        question = [tokenizer.convert_tokens_to_ids(token) for token in sample['question']]\n",
        "\n",
        "        context = context[:self.max_length-len(question)-3]             # Truncate context\n",
        "\n",
        "        input_ids = [self.cls_id] + question + [self.sep_id] + context + [self.sep_id]\n",
        "        token_type_ids = [0] * (len(question) + 1) + [1] * (len(context) + 2)   # <CLS>+question, <SEP>+contexts+<SEP>\n",
        "\n",
        "        if sample['answers'] is not None:\n",
        "            answer = sample['answers'][0]\n",
        "            start = min(len(question) + 2 + answer['start'], self.max_length - 1)\n",
        "            end = min(len(question) + 2 + answer['end'], self.max_length - 1)\n",
        "        else:\n",
        "            start = None\n",
        "            end = None\n",
        "\n",
        "        return {\n",
        "            'guid': sample['guid'],\n",
        "            'context': sample['context_original'],\n",
        "            'question': sample['question_original'],\n",
        "            'position': sample['context_position'],\n",
        "            'input_ids': input_ids,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'start': start,\n",
        "            'end': end\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw41BTIHM9F8",
        "outputId": "39919a53-895e-4d8e-9dc2-6d7bc5682a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.Indexer object at 0x7f8662e6d3a0>\n"
          ]
        }
      ],
      "source": [
        "indexer = Indexer(list(tokenizer.vocab.keys()))\n",
        "print(indexer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdAld-LHNZJs"
      },
      "outputs": [],
      "source": [
        "class IndexerWrappedDataset:\n",
        "    def __init__(self, dataset: TokenizedKoMRC, indexer: Indexer) -> None:\n",
        "        self._dataset = dataset\n",
        "        self._indexer = indexer\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._dataset)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        sample = self._indexer.sample2ids(self._dataset[index])\n",
        "        sample['attention_mask'] = [1] * len(sample['input_ids'])\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyFZqtAdN4oa",
        "outputId": "f6761357-22d7-46fb-ab99-552a2408cc65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "114958"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexed_train_dataset = IndexerWrappedDataset(train_dataset, indexer)\n",
        "indexed_dev_dataset = IndexerWrappedDataset(dev_dataset, indexer)\n",
        "len(indexed_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLTdzq5oN6ro"
      },
      "source": [
        "##Collate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_fk9YaQN9xT"
      },
      "outputs": [],
      "source": [
        "class Collator:\n",
        "    def __init__(self, indexer: Indexer) -> None:\n",
        "        self._indexer = indexer\n",
        "\n",
        "\n",
        "    def __call__(self, samples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
        "        samples = {key: [sample[key] for sample in samples] for key in samples[0]}\n",
        "\n",
        "        for key in 'start', 'end':\n",
        "            if samples[key][0] is None:\n",
        "                samples[key] = None\n",
        "            else:\n",
        "                samples[key] = torch.tensor(samples[key], dtype=torch.long)\n",
        "\n",
        "        for key in 'input_ids', 'attention_mask', 'token_type_ids':\n",
        "            samples[key] = pad_sequence([torch.tensor(sample, dtype=torch.long) for sample in samples[key]],\n",
        "                                        batch_first=True,\n",
        "                                        padding_value=self._indexer.pad_id)\n",
        "\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPOmprtST4E8"
      },
      "source": [
        "##Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Juviv6oT1yc"
      },
      "outputs": [],
      "source": [
        "collator = Collator(indexer)\n",
        "train_loader = DataLoader(indexed_train_dataset,\n",
        "                          batch_size = args.batch_size.train // args.accumulate,\n",
        "                          shuffle = True,\n",
        "                          collate_fn = collator,\n",
        "                          num_workers = 2)\n",
        "\n",
        "dev_loader = DataLoader(indexed_dev_dataset,\n",
        "                        batch_size = args.batch_size.eval,\n",
        "                        shuffle = False,\n",
        "                        collate_fn = collator,\n",
        "                        num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZA_ZTAOT24f",
        "outputId": "49a51882-d8af-48d8-f576-b484a3ea8b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    2,  7754,  4561,  ...,     0,     0,     0],\n",
            "        [    2,  8899,  6887,  ...,     0,     0,     0],\n",
            "        [    2,  6955,  9888,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2,  7487, 12295,  ...,     0,     0,     0],\n",
            "        [    2,  6851,  8298,  ...,     0,     0,     0],\n",
            "        [    2,  6938,  7051,  ...,     0,     0,     0]])\n",
            "torch.Size([32, 1024])\n",
            "['guid', 'context', 'question', 'position', 'input_ids', 'token_type_ids', 'start', 'end', 'attention_mask']\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch = next(iter(dev_loader))\n",
        "print(batch['input_ids'])\n",
        "print(batch['input_ids'].shape)\n",
        "print(list(batch.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QnT9qNwT9ZY"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVyWc3FwpSwm"
      },
      "outputs": [],
      "source": [
        "# 자체 평가를 위한 levenstein-distance\n",
        "\n",
        "def calc_distance(a, b):\n",
        "    ''' 레벤슈타인 거리 계산하기 '''\n",
        "    if a == b:\n",
        "        return 0 # 같으면 0을 반환\n",
        "\n",
        "    a_len = len(a) # a 길이\n",
        "    b_len = len(b) # b 길이\n",
        "    if a == \"\":\n",
        "        return b_len\n",
        "    if b == \"\":\n",
        "        return a_len\n",
        "\n",
        "    matrix = [[] for i in range(a_len+1)]\n",
        "\n",
        "    for i in range(a_len+1):\n",
        "        matrix[i] = [0 for j in range(b_len+1)]\n",
        "\n",
        "    for i in range(a_len+1):\n",
        "        matrix[i][0] = i\n",
        "\n",
        "    for j in range(b_len+1):\n",
        "        matrix[0][j] = j\n",
        "\n",
        "    for i in range(1, a_len+1):\n",
        "        ac = a[i-1]\n",
        "        for j in range(1, b_len+1):\n",
        "            bc = b[j-1]\n",
        "            cost = 0 if (ac == bc) else 1\n",
        "            matrix[i][j] = min([\n",
        "                matrix[i-1][j] + 1,     # 문자 삽입\n",
        "                matrix[i][j-1] + 1,     # 문자 제거\n",
        "                matrix[i-1][j-1] + cost # 문자 변경\n",
        "            ])\n",
        "\n",
        "    return matrix[a_len][b_len]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qah7sm0aT-Pz"
      },
      "source": [
        "##Empty Cuda Cashe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA_-QakIUBsD"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49SwRjGdUFu3"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b6417c9e5f6e43ec807ccd1c11e594c7",
            "c5390134ea304ef981ee2b22b1552c87",
            "aa904bba27514e5d853cfc21e122e8e0",
            "72a1c8b379154b4995d9ffdc087a70f8",
            "456c66659c6247f6a06499a0b5cf2c2f",
            "f60e2ce41f10493d91be93c26e20e449",
            "bb8f5063e76a42db88844d5021dc69cf",
            "81a2610466d440478c5e1dfdb3a4225e",
            "614d5563229b43189707a55c932d5a49",
            "76309ea9985a412884f079510582906c",
            "882b5a5c14db4217b21d17d4a6bc4664"
          ]
        },
        "id": "c-d3yilBUION",
        "outputId": "e2a6b6a0-1737-4cb1-fc01-ee2d74cd2f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 ===============================================================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6417c9e5f6e43ec807ccd1c11e594c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/28740 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 661 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 6.813\n",
            "Valid Loss: 5.725\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "dev_losses = []\n",
        "\n",
        "train_loss = []\n",
        "dev_loss = []\n",
        "\n",
        "loss_accumulate = 0.\n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "#                                               lr_lambda=lambda epoch:0.95**epoch,\n",
        "#                                               last_epoch=-1,\n",
        "#                                               verbose=False)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "best_model = [-1, int(1e9)]\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    print(\"Epoch\", epoch, '===============================================================================================================')\n",
        "\n",
        "    # Train\n",
        "    progress_bar_train = tqdm(train_loader, desc='Train')\n",
        "    for i, batch in enumerate(progress_bar_train, 1):\n",
        "        del batch['guid'], batch['context'], batch['question'], batch['position']\n",
        "        batch = {key: value.cuda() for key, value in batch.items()}\n",
        "\n",
        "        start = batch.pop('start')\n",
        "        end = batch.pop('end')\n",
        "\n",
        "        output = model(**batch)\n",
        "\n",
        "        start_logits, end_logits = output.start_logits, output.end_logits\n",
        "\n",
        "        loss = (F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)) / args.accumulate\n",
        "        loss.backward()\n",
        "\n",
        "        loss_accumulate += loss.item()\n",
        "\n",
        "        del batch, start, end, start_logits, end_logits, loss\n",
        "\n",
        "        if i % args.accumulate == 0: # gradient accumulation\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=False)\n",
        "\n",
        "            train_loss.append(loss_accumulate)\n",
        "            progress_bar_train.set_description(f\"Train - Loss: {loss_accumulate:.3f}\")\n",
        "            loss_accumulate = 0.\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if i % int(len(train_loader) / (args.accumulate * 50)) == 0:\n",
        "            # Evaluation\n",
        "            for batch in dev_loader:\n",
        "                del batch['guid'], batch['context'], batch['question'], batch['position']\n",
        "                batch = {key: value.cuda() for key, value in batch.items()}\n",
        "\n",
        "                start = batch.pop('start')\n",
        "                end = batch.pop('end')\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    output = model(**batch)\n",
        "\n",
        "                    start_logits = output.start_logits\n",
        "                    end_logits = output.end_logits\n",
        "                model.train()\n",
        "\n",
        "                loss = F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)\n",
        "\n",
        "                dev_loss.append(loss.item())\n",
        "\n",
        "                del batch, start, end, start_logits, end_logits, loss\n",
        "                scheduler.step()\n",
        "\n",
        "            train_losses.append(mean(train_loss))\n",
        "            dev_losses.append(mean(dev_loss))\n",
        "            train_loss = []\n",
        "            dev_loss = []\n",
        "\n",
        "\n",
        "            if dev_losses[-1] <= best_model[1]:\n",
        "                best_model = (epoch, dev_losses[-1])\n",
        "                model.save_pretrained(f'models/{args.NAME}_{epoch}')\n",
        "            wandb.log({\"train_loss\": train_losses[-1],\n",
        "                       \"valid_loss\": dev_losses[-1]})\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Train Loss: {train_losses[-1]:.3f}\")\n",
        "    print(f\"Valid Loss: {dev_losses[-1]:.3f}\")\n",
        "    print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8lGLvIoUTFq"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDN8w1A6UUZd"
      },
      "source": [
        "##Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JMmUc0IIUWNx",
        "outputId": "e7baafc2-aa01-4781-c8cb-0b10621c4a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Test Samples:  4008\n"
          ]
        }
      ],
      "source": [
        "test_path = '/content/drive/MyDrive/Groom_8th_project2/test.json'\n",
        "test_dataset = TokenizedKoMRC.load(test_path)\n",
        "indexer_test = Indexer(list(tokenizer.vocab.keys()))\n",
        "indexed_test_dataset = IndexerWrappedDataset(test_dataset, indexer_test)\n",
        "print(\"Number of Test Samples: \", len(test_dataset))\n",
        "# print(test_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m3oQx15VQO_"
      },
      "source": [
        "##model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6a6SVI1dVSqi",
        "outputId": "6b4cddfb-6fcd-4f53-bfbe-48f8c7133d54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "riJopwghVV2V"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(f'models/{args.NAME}_{best_model[0]}')\n",
        "model.cuda();\n",
        "# summary(model, (args.batch_size.train//args.accumulate, args.max_length), dtypes=['torch.IntTensor'], device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hdG_Gi5IVXMK",
        "outputId": "80cbed50-ec35-4ec9-bb87-fbe9c076be4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 397 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------1------\n",
            "Context: 우리나라 철강산업의 성장을 위해환경과 에너지 효율의 경쟁력을 높여야 한다는 주장이 제기됐다.김주한 산업연구원 박사는25일 대치동 포스코센터에서열린 제35회 철강산업포럼에서 글로벌 금융위기 이후 한국 철강산업 현황 점검과 경쟁력 제고 전략이라는 주제 발표에서 국내 철강산업은 성숙기에 달했지만 향후 지속적인 발전을 위해서는원료의 안정적 확보로 원가경쟁력을 제고해야 한다고 말했다. 김 박사는 또 글로벌 시장을 목표로 하는 공급체계를 구축하며 산업내 협력과 연계성 제고를 통한 산업생태계 강화 환경 및 에너지 효율성 강화가 필요하다고 지적했다. 이안 크리스마스 전 세계철강협회 사무총장은 세계 철강산업 전망 기조연설에서 세계 철강업계의 도전과제로 소재간 경쟁 중국의 과잉설비 불확실한 원료전망 인력확보와 안전 환경문제를 꼽았다. 세계 철강업계의 지속적인 발전을 위해서는 생산 및 비용의 유연화를 통한 수익성 확보 규모보다 부가가치에 초점을 둔 경영 고객요구에 부응한 연구개발R&amp;D; 제고 안전하고 창의적인 노무환경 녹색환경기술 확보 정부보조금 억제를 통한 시장왜곡 최소화가 필요하다고 주장했다. 오일환 철강협회 상근 부회장은 개회사를 통해 한중일 3국 협력제계를 제안했다. 한중일 동북아 3국의 조강생산량은 세계 조강생산의 56% 철강수요는 54%의 비중을 차지하고 있다. 철강수요면에서 보면 자동차 생산은 전세계 생산량의 42% 조선은 전세계 건조량의 86%다.\n",
            "Question: 제35회 철강산업포럼은 언제 열렸는가?\n",
            "Answer: 25일\n",
            "\n",
            "------2------\n",
            "Context: 미국이 이라크 침공 이유로 내세웠던 대량살상 무기를 찾아내기 위해 지난 2년 동안 1700여명의 요원을 투입해 벌여온 무기 수색작업을 지난달 슬그머니 끝낸 사실이 12일 밝혀졌다. 스콧 매클렐런 백악관 대변인은 이날 정례 브리핑에서 조지 부시 대통령이 지난달 찰스 듀얼퍼 이라크서베이그룹ISG 단장을 만나 그동안의 노고를 치하했다며 이라크에 있으리라 생각했던 대량살상 무기는 거기 없었다고 밝혔다. 그는 사실상 활동은 끝났으며 일부 요원이 최종 보고서를 준비하고 있다고 덧붙였다. 이로써 미국이 이라크 침공의 근거로 내세운 대량살상 무기 프로그램은 존재하지 않는다는 게 최종적으로 확인됐고 부시 행정부는 거센 비판을 나라 안팎에서 받을 것으로 보인다. 이라크에 대량살상 무기가 없다는 건 지난해 9월 듀얼퍼 단장이 중간보고서를 낼 때도 이미 알려졌다. 그러나 대선을 코앞에 뒀던 당시 부시 행정부는 여전히 수색이 진행 중이라며 발견 가능성을 배제하지 않았다. 대선이 끝난 뒤인 지난달 부시 대통령은 듀얼퍼 단장을 만나 활동종료 보고를 받았지만 이를 공개하지 않았다. 이 사실은 가 이날 아침에 듀얼퍼는 고향에 돌아왔고 분석가들도 버지니아 랭리의 중앙정보국 본부로 복귀했다고 보도하면서 처음 알려졌다. 이 보도 직후에야 비로소 백악관과 국방부 관리들은 수색작업의 완전중단 사실을 언론에 확인해줬다. 이날 낮 백악관 정례 브리핑에선 미국의 신뢰성이 엄청난 타격을 받은 것 아니냐 부시 대통령은 지금 북한과 이란이 핵 또는 핵프로그램을 가졌다고 말한다. 그러나 세계의 다른 나라들은 우리가 그걸 어떻게 믿겠느냐고 말하지 않겠나란 질문도 나왔다. 낸시 펠로스 민주당 하원 원로는 성명을 내고 부시 대통령은 자신의 잘못을 미국민들에게 밝히고 왜 틀렸는지를 해명해야 한다고 공격했다. 6g워싱턴박찬수 특파원\n",
            "Question: 대량살상 무기를 이유로 이라크를 침공한 나라는 ?\n",
            "Answer: 미국\n",
            "\n",
            "------3------\n",
            "Context: 한 보고서에 의하면 일생 동안 오르가슴을 한번도 경험하지 못하는 여자의 비율은 5% 정도인 데 반해 후천성 불감증은 30%나 된다고 한다. 애초부터 감이 없는 사람의 불감증보다 후천적 요인으로 불감의 상태에 돌입하는 경우가 훨씬 많다는 말이다. 도덕적 불감증도 후천적인 경우가 대부분이다. 처음에는 예민했는데 환경적 요인을 이유로 서서히 감각을 포기하는 것이다. 불감증의 또다른 사회적 이름은 관행이다. 불감증에 걸린 집단과 개인이 많은 사회일수록 불가사의한 관행들이 괴력을 발휘한다. 관행은 핵심감정이 결여된 행위다. 관행의 가장 큰 문제는 애초부터 본질을 못 보게 하거나 일부러 외면하게 만드는 것이다. 지엽적 문제에 몰두하여 본질이 사라지는 경우가 허다하다. 〈문화방송〉 의 양심고백에서 출발한 구치백 파문은 그러한 관행의 한 단면을 극명하게 보여준다. 사건의 개요도 그렇고 그것을 다루는 언론의 태도도 그렇다. 대부분의 언론은 그 사건의 핵심을 내부고발이냐 개인의 공명심이냐로 양분한다. 하지만 내가 보기에 그 사건의 본질은 언론인으로서 자본과의 관계설정을 치열하게 고민하는 한 중견기자의 자기성찰에 있다. 문제제기 방식의 타당성이나 타이밍 등은 지엽적인 것에 불과하다. 윤종훈 회계사가 부유세 문제에 관한 심적 갈등을 토로하고 민주노동당을 떠나자 왜 당내의 일을 안에서 풀지 외부 언론에 흘려 당의 명예를 훼손시키냐며 특정 목적이 있는 것이 아닌가라는 비난이 흘러나왔다. 이 기자에게도 비슷한 힐난이 반복되지만 그에게 특정 목적이 있다면 그것은 자신을 포함해 자본에 적 감각이 마비된 불감증에 대한 고백성사인 듯 보인다. 전임 문화방송 사장이었던 김중배씨가 언론은 이제 권력과의 싸움에서 보다 원천적인 제약 세력인 자본과의 힘겨운 싸움을 벌이지 않으면 안되는 시기에 접어들었다고 선언하며 〈동아일보〉 편집국장 자리를 내던진 것이 1991년이다. 그 힘겨운 싸움이 본격적이고 지속적으로 진행되고 있다는 한 증거가 이 기자의 양심고백이라고 나는 생각한다. 벽을 등지고 싸우면 백명과 싸워도 이길 것이라는 평가를 받던 전설적인 싸움꾼 시라소니는 결국 360도 적으로 둘러싸인 싸움에서 결정적으로 패해 주먹계를 떠났다. 언론이 권력과 각을 세우는 것은 벽을 등에 지고 하는 상대적으로 안전한 싸움이다. 권력과 맞서면 동아일보 백지광고 사태 때 국민들이 힘을 모아준 것처럼 확실한 지원세력이 생겨서 쉽게 무너지지 않는다. 하지만 자본과의 접전은 사방에 둘러싸인 적에 맞서 홀로 360도를 돌며 싸워야 하는 전방위 싸움이다. 피아의 경계마저 확실치 않아 자기합리화의 유혹을 느끼기 십상이다. 기자의 문제만은 아닐 것이다. 소규모라도 의사들의 모임이 있으면 제약회사에서 나와 식대를 지불하는 경우가 적지 않다. 1인당 3만4만원 정도 갹출하면 해결될 일을 일부 의사들은 관행을 앞세워 기꺼이 자본의 힘을 빌린다. 그런 자리에서 정색을 하고 자본과 의료의 결탁을 비판하는 일은 쉽지 않다. 이 기자도 문제가 된 식사 자리를 박차고 나오지 못한 이유에 대해 그동안 회사에서 늘 데리고 있기 힘든 놈으로 찍힌 것에 대한 부담이 있었다고 고백한다. 그의 작은 허물까지 다 이해해야 한다는 말이 아니라 자본과의 싸움은 그만큼 인간적이고 미묘하며 전선이 불명확하다는 얘기다. 그런 싸움에 나선 이 기자의 양심고백을 쌍권총 쏘아대는 홍콩 활극의 주인공처럼 바라보는 시각은 지극히 관행적이다. 김중배 선언이 자본의 언론통제에 경종을 울리는 역사적 시작인 것처럼 이 기자의 양심고백 또한 자본에 의 불감증을 자기매질하는 이상호 선언으로 자리매김될 수 있도록 사안의 본질이 훼손되지 않았으면 좋겠다. 이상호로 대변되는 들이 지금처럼 자본에 대한 민감함을 유지할 수 있는 한 나는 그들이 결국엔 자본과의 전방위 싸움에서 승리를 거둘 것이라고 굳게 믿는다. 아낌없는 지지를 보낸다. 정혜신 정신과 전문의\n",
            "Question: 윤종훈 회계사가 떠난 당은 어디인가?\n",
            "Answer: 한 보고서에 의하면 일생 동안 오르가슴을 한번도 경험하지 못하는 여자의 비율은 5% 정도인 데 반해 후천성 불감증은 30%나 된다고 한다. 애초부터 감이 없는 사람의 불감증보다 후천적 요인으로 불감의 상태에 돌입하는 경우가 훨씬 많다는 말이다. 도덕적 불감증도 후천적인 경우가 대부분이다. 처음에는 예민했는데 환경적 요인을 이유로 서서히 감각을 포기하는 것이다. 불감증의 또다른 사회적 이름은 관행이다. 불감증에 걸린 집단과 개인이 많은 사회일수록 불가사의한 관행들이 괴력을 발휘한다. 관행은 핵심감정이 결여된 행위다. 관행의 가장 큰 문제는 애초부터 본질을 못 보게 하거나 일부러 외면하게 만드는 것이다. 지엽적 문제에 몰두하여 본질이 사라지는 경우가 허다하다. 〈문화방송〉 의 양심고백에서 출발한 구치백 파문은 그러한 관행의 한 단면을 극명하게 보여준다. 사건의 개요도 그렇고 그것을 다루는 언론의 태도도 그렇다. 대부분의 언론은 그 사건의 핵심을 내부고발이냐 개인의 공명심이냐로 양분한다. 하지만 내가 보기에 그 사건의 본질은 언론인으로서 자본과의 관계설정을 치열하게 고민하는 한 중견기자의 자기성찰에 있다. 문제제기 방식의 타당성이나 타이밍 등은 지엽적인 것에 불과하다. 윤종훈 회계사가 부유세 문제에 관한 심적 갈등을 토로하고 민주노동당을 떠나자 왜 당\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for idx, sample in zip(range(1, 4), indexed_train_dataset):\n",
        "    print(f'------{idx}------')\n",
        "    print('Context:', sample['context'])\n",
        "    print('Question:', sample['question'])\n",
        "\n",
        "    input_ids, token_type_ids = [\n",
        "        torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
        "        for key in (\"input_ids\", \"token_type_ids\")\n",
        "    ]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
        "\n",
        "    start_logits = output.start_logits\n",
        "    end_logits = output.end_logits\n",
        "    start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "\n",
        "    start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "    end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "\n",
        "    probability = torch.triu(start_prob[:, None] @ end_prob[None, :]) # triangle upper matrix\n",
        "\n",
        "    index = torch.argmax(probability).item() # joint prob matrix에서 max_probability return\n",
        "\n",
        "    start = index // len(end_prob)\n",
        "    end = index % len(end_prob)\n",
        "\n",
        "    start_str = sample['position'][start][0]\n",
        "    end_str = sample['position'][end][1]\n",
        "\n",
        "    print('Answer:', sample['context'][start_str:end_str] + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "a4feda0d90624848821ec687b17baa01"
          ]
        },
        "id": "uB2mZWWeqjPP",
        "outputId": "ae5eb49e-6f2e-4c0e-9ca6-0ef1ac179474"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4feda0d90624848821ec687b17baa01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing:   0%|          | 0/4008 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "os.makedirs('out', exist_ok=True)\n",
        "with torch.no_grad(), open('out/baseline.csv', 'w') as fd:\n",
        "    writer = csv.writer(fd)\n",
        "    writer.writerow(['Id', 'Predicted'])\n",
        "\n",
        "    rows = []\n",
        "    for sample in tqdm(indexed_test_dataset, \"Testing\"): # tqdm(, str) 창 옆에 문자열추가\n",
        "        input_ids, token_type_ids = [\n",
        "            torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
        "            for key in (\"input_ids\", \"token_type_ids\")\n",
        "        ]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
        "        start_logits, end_logits = outputs[0], outputs[1]\n",
        "\n",
        "        start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "\n",
        "        start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "        end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "        probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "        index = torch.argmax(probability).item()\n",
        "\n",
        "        start = index // len(end_prob)\n",
        "        end = index % len(end_prob)\n",
        "\n",
        "        start = sample['position'][start][0]\n",
        "        end = sample['position'][end][1]\n",
        "\n",
        "        rows.append([sample[\"guid\"], sample['context'][start:end]])\n",
        "        rows.append([sample[\"guid\"], sample['context'][start+1:end+2]])\n",
        "\n",
        "    writer.writerows(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs3bghYUULBW"
      },
      "source": [
        "# Post processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xCz9MG27aiMn",
        "outputId": "d918f710-e6b3-4b4b-c573-33aa5fa092b6"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e68d6514f4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mguid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "rows_ = rows\n",
        "import numpy as np\n",
        "lens=[]\n",
        "for row in rows_:\n",
        "  for guid, ans in row:\n",
        "    lens.append(len(ans))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U63EtC-jVg8O"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Vd1GQlscTOr0",
        "outputId": "d3e79c59-f054-467f-ce08-91f625dfe9f7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(lens, bins = 12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siV2Y0XXpkb7"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjZ7S0YElNQb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Groom_8th_project2/baseline_post_processing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY7Kya0ppw2A"
      },
      "outputs": [],
      "source": [
        "sub = sub.fillna(\"\")\n",
        "pred = list(sub['Predicted'])\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lens = []\n",
        "for i in pred:\n",
        "  lens.append(len(i))\n",
        "\n",
        "\n",
        "plt.hist(lens)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QoSKPGMM0SAi",
        "outputId": "26323ec1-980f-434f-cf72-354103966404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx,i in enumerate(pred):\n",
        "  if len(i)>10:\n",
        "    pred[idx] = ''\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jIfL2P-4JTF",
        "outputId": "8b5b59d5-e73c-4a0f-d385-46ea1aabfedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '', '링크트인', '링크트인', '마드리드', '', '5조원', '', '중합시켜', '노르웨이', '22개', '필리핀', '김교성', '79달러', '존 위클리프', '얀 후스', '지기스문트', '복정역', '법무법인 한울', '', '', '키프로스 섬', '독일', '보석', '', '부레', '프리오노수쿠스', '이산화탄소', '척추', '분류학적 접근', '', '손병석', '', '공직자윤리법', '8월 20일', '현실색', '19조원', '9월22일', '소련 헌법', '인도', '', '갈릴레오', '프라하', '히파르코스', '', '577편', '각막 궤양이', '', '2000만원', '개혁파', '조개류', '아드레날린', '6일', '레이다', '', '도로스', '연방군 수뇌', '샤아 소좌', '쿠니스', '', '', '식품위생법', '이디야', '8개 동의', '5억원', '2004년', '', '2008년', '민간인', '41개', '핵', '데프레닐', '미용', '고려은단', '쿠에농강', '50인치 TV', '', '박씨(朴氏)', '등산 스틱', '70선', '이달 17일', '', '', '3000억원', '', '3만원', '강승훈', '서울시', '19단계', '바리사이파', '이준용', '', '박영효', '강원도관찰사', '이기혁', '불과 한 살', '', \"'동물'\", '2만3000명', '불어', '박중양', '', '연 4%', '지난 6월5일', '하라 감독', '', '', '무함마드', '봉건제', '위원장', '도쿄', '', '독일 인민당', '117.8%', '여름철', '14건', '2016년', '', '한미약품', '일본', '청산염', '', '납중독의 위험', '', '동전 던지기', '', '10년', '19.8%', '김범수', '', '초음파', '모험 이행', '', '', '13시간', '일본', '184만원', '사포', '63.7%', '2012년', '중국 공상은행', '이달 말', '', '', '2부로', '연 2.25%', '1만건', '사회문화', '조선무선강습소', '발전기', '보육 예산', '전송속도', '톰 휠러', '1억원', '51개', '대법원', '쉴드 빔', '', '경제정책국장', '안일환', '경기 평택', '25일', '민당(CHP)', '11.9%', '신테카바이오', '조지 닐센', '베스 앤', '지난 1월', '제13대', '베트남', '기독교의 확산', '', '네덜란드', '고태용', '', '‘빨대족’', '라위스달', '카이저', '대우증권', '2011년', '홍기택', '30권', '', '에베소', '5만2000원', '한국', '1시간', '5일', '세아특수강', '2500억원', '6개국', '정교회 교리', '증권업', '절도사', '요새', '28일', '박근혜 대통령', '', '', '배터리', '864년', '5.1%', '점수', '', '아우토슈타트', '블랙록', '유화제', '2년', '32주', '웹사이트', '일반대화', '극작가', '경제부총리', '', '', '벵골 분할령', '2006년', '', '6월', '김동식', '', '1848년', '1817년', '영국', '', '왕건', '석총', '오경식', '', '1993년', '2009년', '', '2002년', 'HOBM', '이란', '박재욱', '히타치', '기상 악화', '', '말리크', '하원의 동의', '1948년', '카르멜 수녀원', '', '김수환', '이승만', '', '국무 총리', '젊은 과격파', '', '6.5', '제너럴모터스', '달', '국회 의원회관', '사은품', '지난해 9월', '30%', '유럽연합', '', '마르클란드', '안상환', '11세기 중엽', '가즈사 국', '국립중앙박물관', '프랑스', '금대야', '392달러', '유류비 부담', '', '키루스 2세', '박근혜 대통령', '중종', '강녕전', '12세', '', '', '', '런던', \"'황제'\", '2월', '4~6시간', '이틀', '동아ST', '도버 밀', '흑인요소', '민성은행', '교수', '25g', '소비에트 시대', '지난해 12월', '30일', '일본', '1978년', '권도엽', '국가안보상', '지난해 7월', '300억달러', '10월', '', '금융위원회', '김부선', '7000대로', '', '철판', '', 'CDS', '민주당', '아테네올림픽도', '3일', '', '8월 26일', '마술사들', '‘역삼 자이’', '5월', '정유공장', '', '문간채', '천다오밍', '얼웨허', '백성들', '순치제', '463개', '안드로이드', '워털루대', '두 시간', '', '', '36%', '서울 삼성동', '인도', '', '광주', '생태계', '샤오미', '23일', '청소년', '', '남측 기자실', '프랑스', '‘파로스’', '서예지', '', '윤치호', '1916년', '윤웅렬', '이승만', '1934년', '다산 정약용', '', '', '', '스파크 EV', '', '79점', '캐슬렉스 제주', '세라믹', '15%', '10%', '36.1%', '1978년', '2000달러', '권오준', '‘스노우’', '15일', '', '', '', '', '4.3명', '2층', '', '', '', '', 'AUO', '뽕짝', '김영하', '', '', '나라살림연구소', '1994년', '1988년', '', '입법권', '3824명', '', '방송계', '2018년', '', '서사하라 국경', '298㎞', '', '[스위니토드]', '25.7%', '쏘카', '', '‘유린 타운’', '', '조영달', '2017년', '2017년', 'M1라인', '', '', '', '14명', '48.6%', '', '아시아', '홍콩', '1933년', '9월23일', '5억원', '‘음악서랍’', '수석 부사장', '서대문구청장', '17.6%', '지난 10월', '배터리', '난징', '프로듀서', '노르만족', '위도 대주교', '니케아', '1천 달러', '공공택지', '', '410억원', '410억원', '뉴욕', '워싱턴포스트', '마레', '', '김영과', '아우디', '', '탈동조화)', '1천원', '', '24건', '', '', '', '12개', '', '정교회', '카자흐스탄', '', '존 카리아니', '조지 소로스', '2009년', '청일 전쟁', '장시성', '마오쩌둥', '홈쇼핑', '4명', '공화파 민병대', '6시 45분', '현대전자', '15년', '‘사람인’', '16일', '짐 크래머', '대두식품', '', '9월', '5명', '10개', '근속 연수', '2만4900원', '모스크바', '스웨덴', '6000번대', '303고지', '', '1987년', '지난해 9월', '', '중고가 시장', '', '', '', '18.6%', '장성근', '', '', '원주시', '포르투갈', '6량', '', '김우수', '앙리 블랑슈', '보수당', '미래창조과학부', '13일', '척력', '38%', '2009년', '‘디셈버’', '12일', '민현준', '아르헨티나', '', '13개', '포도 농장', '지난해 10월', '9일', '9일', '외무장관', '', '2층', '', '', '205개', '', '이동건', '', '닌텐도', '박지원', '미국', '', 'KOTRA', '40대', '', '리에주 전투', '나성린', '이명수', '4일', '자유주주의', '영국', '진시황', '여름', '퓨처플레이', '충칭', '1922년', '2년 반', '30일', '2.5%', '1807년', '', '', '4척', '15일', '마르세유', '최형문', '', '3552억원', '한국항공협회', '', '기원전 45년', '베르길리우스', '', '외환은행', '웰컴저축은행', '세한대', '<장야2>', '', '', '', '티레니아 해', '지난 25일', '', '채제공', '‘배따라기’', '진청시티', '김삼룡', '', '<퓨처맨>', '1819년', '포스코', '1962년', '', '17억원', '14~15세기', '‘학교’', '미쓰히데 군', '성철(이영주)', '퀸티아누스', '갤럭시S5', '', '4.23%', '전안와창', '‘아르떼비노’', '강석인', '진솔', '‘호텔숙박세’', '젠하이저', '', '', '61.5%', '생산라인', '', '9.7%', '필 서명', '89곳', '뇌졸중', '', '', '피자헛', '브리지 판', '25조원', '대기원근법', '', '', '2심 재판부', '1건', '내부 설계', '수소 원자', '', '인디고 (쪽)', '1200개', '영국', '로렌스', '현대백화점', '신한카드', '', '페이팔', '박승호', '', '2008년', '', '18건', '20%', '2018년', '20일', '메탄', '', '안티트롬빈', '', '기업세션', '나사로의 부활', 'LG디스플레이', '37.6%', '로웰 천문대', '삼성SDI', '보상', '', '신경숙', '연 3.3%', '서울 금천구', '유황', '의회파', '엠코타운', '42.3%', '1985년', '30%', '공장', '이동근', '', '13일', '광주은행', '7.7%', '임호텝', '', '정신분석학', '', '최면술', '지난 12일', '50억달러', '', '해운대', '', '롯데자이언츠', '', '문제해결 능력', '', '지난달 17일', '포스코', '부산고등법원', '광진상공', '이상호', '', '', '', '1802년', '', '60%', '1만가구', '', '1856년', '', '420여명', '', '독일', '', '1945년', '35개', '', '8층', '지난 26일', '', '민간인', '노르망디', '히틀러의 외투', '대관령', '서남 방언', '이오테크닉스', '', '', '블루투스', '조현기', '필리핀', '만도', '', '왕세충', '기원전 90년', '2008년', '감광층', '', '타이탄', '오카자키', '', '제동거리', '', '', '', '46.2%', '유리', 'CTO', '540억달러', '', '물리학자', '78', '어 지승호 씨', '나쓰코', '시진핑', '', 'LG디스플레이', '말', '2001년', '서울대', '인터지스', '오전 11시', \"'소요유'\", '이탈리아', '독일', '우드로 윌슨', '', '드라', '선거인단', '', '4월12일', '', '근대철학', '35개', '', '명예훼손', '', '116억원', '6대 왕', '', '35%', '', '평양 부민들', '화공', '뉴질랜드', '', '', '셔틀 앱', '유럽인', '보이저 2호', '제5의 물결', '3인', '상의', '강세황', '10단계', '462건', '', '최진호', '어린이들이', '빈목 지역', '바코드 쿠폰', '대한민국 동해', '', '외조모', '보테가베네타', '', '1924년', '가톨릭 교회', '동남해안', '1400만명', '50%', '신동빈', '브릭링크', '62.8kg', '998원14전', '', '시나위 대금', '디즈니랜드', '1992년', '아트레우스', '123억원', '', '3일', '', '', '', '네케르', '17세기 전반', '', '프랑스', '크리스 웨버', '12년', '아산정책연구원', '상품개발팀', '', '', '외환죄 혐의', '《동아일보》', '임정 국무위원', '돈둡 왕첸', '51.4%', '팀 리', '', '', '이홍선', 'TG앤컴퍼니', '유방', '25일', '', '10월', '우피 골드버그', '독일', '15.3%', '한지', '20여분', '48.2%', '반도체사업부', '2003년', '화웨이 워치', '리지 연개소문', '설인귀', '일본', '', '지난 8월', '인도', '터빈 판사', '5개', '주공5단지', '관할 동사무소', '9월', '35년', '중국', '30억 원', '새정치민주연합', '', '2019년', 'CP0의 요원', '경찰관', '마스조', '호림박물관', '15분', '감옥', '', '', '‘B’ 엔진', '류성렬', '', '조코위', '애드허스키', '내년 1월', '2년', '80만㎾', '1800W', '다나베', '', '235억원', '이달 18일', '제조업', '도서벽지지역', '1997년', '인천', '', 'B2G사업', '', '추성훈 씨', '지난 3월', '순천고', '', '', '', '매일', '형 이승은', '10배', '', '이재용', '', '', '석영반암', '문창극', '9510가구', '기관투자', '스페인', '군사 헬리콥터', '', '중국', '설 연휴 직후', '2.5%', '9년', '25대', '43가구', '@design', '', '', '존 레이놀즈', '민정기', '도시바', '중국 상하이', '1935년', '8000개', '35개', '최정빈', '', '', '105인치', '50%', '', '곧 볼바라', '개발 주기', '', '', '19일', '', '셀주크인들', '현 정도원', '2012년', 'TV 셋톱박스', '139만원', '4.4%', '조동규', '', '존 로크', '트루먼', '3월28일', '', '', '지난 13일', '', '교육부 장관', '15명', '1763년', '제5보병대', '', '액화천연가스', '훈고학', '', '영국', '포트해필턴', '학(천주교', '', '', '집배원', '4916원', '4916원', '1839년', '', '', '온미디어', '2017년', '', '동아일보', '솔빛섬', '3년', '관료주의', '44원', '버트런드 러셀', '', '', '리먼브러더스', '3.70달러', '', '감소', '2016년', '광주광역시', '', '고교 부문', '11일', '야리스', '9만9000원', '호메이니', '', '5명', '2개', '1396명', '2001년', '15일', '라이엘', '', '오리온그룹', '12일', '', '8만대', '로버트 달', '', '농민', '2월', 'SBS', 'UNKRA', '민음사', '', '독일', '16만400명', '23일', '추축국', '3.1천만', '', '일본', '39.6%', '삼성전자', '이마그니페르', '19일', '마이크 셔먼', '', '캐나다', '3점', '도서해안굿', '혜주의 집', '100억원', '선물', '지난달', '아딜 아카', '', '', '', '2018년', '군도', '‘JNK’', '', '생활가', '독립적 기구', '엘림스 스마일', '', 'GS칼텍스', '삼립식품', '29일', '에이티아이', '광고', '고등학생', '', '', '', '반도건설', '다음달 18일', '', '', '네스토리우스', '국가계약법', '2012년', '4명', '‘ZENZ’', '', '부친', '박갑동', '장덕수', '1937년', '강덕상', '1946년', '5인', '', '김규식', '소설가 김동인', '', '3개', '알체라', '뉴욕', '1433년', '', '슈코르체니', '', '《킬 빌》', '', '‘아너6’', '조웅래', '15위', '1821년', '', '잡스', '일본인', '닥나무', '2013년', '52억원', '10위', '미국', '통제선', '18개', '', '1995년', '요미우리', '', '이경', '', '안홍철', '변호사', '7일', '닛산', '이서현', '배추', '칼빈주의', '50세', '마츠키 촌', '시구 번역', '메스코스틸', '', '서요섭', '1891년', '1959년', '반도건설', '', '이승준', '', '덴소', '러시아', '활성산소', '마이크로소프트', '', '평화주의자', '5년', '6일', '마포대교', '우리은행', '오는 29일', '유명인사들이', '공정거래위', '', '1931년', '코케인의 땅', '6091개', '‘단칸지수’', '100여점', '', '2003년', '5㎜', '1255의 1', '', '홉스', '발렌스', '', '대전', '90.9%', '텍사스주', '도요다 에이지', '', '화흡', '올리버 색스’', '1년', '551년', '이정란', '', '2009년', '5400억원', '', '11월', '벤자민 버틀러', '', '', '‘디베이트북’', '서남쪽', '자연환경해설사', '', '김태호', '', '리스크관리본부', '새만금개발청', '산업통상자원부', '고려 말', '고려 말', '4200억원', '', '삼성엔지니어링', '자치통감', '18일', '', '1362년', '1362년', '프랑스', '지재권 전략', '9시7분', '96kHz', '', '', '중앙은행업', '', '29일', '10%', '런던', '‘메멘토’', '14~24일', '130억유로', '무료', '8만4000건', '', '중소기업', '2012년', '우주해적단', '22일', '', '송광조', '', '', '조영희', '94억달러', '도쿠시마현', '처칠', '우유', '', '12.7%', '8일', '삼성그룹', '내년 3월', '한국', '', '다섯 달', '일본', '1000억원', '', '50만원', '연 3.3%', '', '편지', '', '물질특허', '버킨', '439억원', '배회 몬스터', '술집', '다음카카오', '강남구', '', '안티오키아', '상인', '물 주입', '소니', '1878년', '', '전기차', '299.8%', '', '21일', '', '4명의 사냥꾼', '작년 7월', '윤동원', '', '감염내과 분야', '40억달러', '히사시 오하시', '8월 15일', '', '20개', '', '86㎡', '부사장', '나진항', '', '', '', '트리톤', '', '반경 30㎞', '10월', '정쩌광', '망주석', '‘롤앤밥스’', '지구', '다음달 1일', '3건', '11일', '용인', '11월 19일', '2011년', '유상호', '도로', '1966억원', '액체', '1만3800원', '', '시골소녀', '25개', '9개사', '', '중국', '', '작은 논쟁', '', '21일', '계양군', '대전', '복호나한', '10명', '납', '‘AA-’', '바이올리니스트', '대공 삼중주', '', '‘서피스북’', '경기지방경찰청', \"'백범일지'\", 'UBS', '2015년', '', '31일', '24일', '하나금융지주', '오스트리아', '현대상선', '2011년', '', '', '', '이병기', '2011년', '2007년', '', '종 맨 위', '청진기', '김동재', '배우자', '', '', '', '', '기마대지휘관', '번장정', '한진해운', '가속화 분류기', '1800만t', '보조 손잡이', '부엉이', '25살', '2011년', '융합이공대학', '냉전 종식', '‘2018년', '2009년', '미국', '오길한', '', '', '우천', '오고 히로시', '강원 원주시', '지난 23일', '2.2병', '47개', '6개', '', '스타트업', '', '66명', '모바일', 'SK텔레콤', 'LG유플러스', '서비스 산업', '1984년', '황금못', '고주파', '최일성', '', '', '트로츠키주의파', '순수익', '', '다음달 31일', '', '입찰가', '', '하태경 의원', '경기 안산시', '', '', '334조달러', '334조달러', '투기세력', '1867년', '이연희', '9억원', '', '30여개', \"'무핵 생물'\", '무성 생식', '만 26세', '', 'SK하이닉스', '290명', '', '', '11일', '', '선덕여왕', '화가', '10억원', '항공통제사', '나무 위', '이명박정부', '미국', '', '김영록', '군대', '1866년', '안게바 공격', '나검색 씨', '비밀결사주의', '', '', '나라방송', '김외현', '94개', '‘만리자이’', '쌍용건설', '닛산', '‘까두’', '서울대', '멕시코', '55세', '루시더스캐피털', '김우중', '니치렌정종', '6.2%', '나뭇잎', '2조원', '4.1%', '오야마 이와오', '투키디데스', '', '’DOL잔치’', '크루 공장', '결핵', '샤를르칸', '10개', '중국', '', '김철규', '오토나이트비전', '홈플러스', '체사레 보르자', '', '2014년', '120억원', '8,704개', '민주당', '72%', '스티브 잡스', '', '60개', '벵자멩 밀피예', '호모 사피엔스', '방재시험연구원', '참호', 'IEA', '', '법인세', '', '', '암말로', '', '', '티볼리', '', '20일', '자유송환', '2.8%', '아니카 프라곳', '', '자동차 산업', '시크 제국', '베이징', '최고재무책임자', '', '', '2011년', '', '8월27일', '15개', '', '주니치전', '우리은행', '15일', '한민구', '', '5층', '', '2013년', '캠코', '대중음악', '하대', '6억여 엔', '요한 카시안', '46.5%', '', '뉴스 헤드라인', '건국대학교', '우부승지', '현대자동차그룹', '8월1일', '나무', '경영학', '일본', '7일', '박근혜 대통령', '', '', '', '중국', '집행유예', '영어', '', '102억원', '열두 살', '열두 살', '', '', '바이두', '', '서울사이버대', '대구은행', '28만원', '8억유로', '', '김상재', '', '필립 토비아스', '', '', '14곳', '', '지난달 20일', '양산시', '일본', '', '‘브이(V)’', '14일', '레터맨', '연 2.7%', '', '파라오', '20대', '', '10월 31일', '', '얄마르 샤흐트', '알렉산더 겜린', '', '미분양지수', '', '2002년', '하이게이트', '벨바스트 월드', '2010년', '잉락 친나왓', '2008년', '', '황산화', '2016년', '11월', '루뭄바', '48개월', '연령 역차별', '김창권', '교도관', '보병', '권태기', '', '봄', '천후산 문수사', '', '', '', '자오 타오', '태백산국립공원', '대구', '32개', '물자체', '경차 모닝', '안전진단', '심폐기능 발달', '서울', '쿠팡', '강남구', '중형 로펌', '일본인', '2년제', '', '윌리엄 모리스', '2014년', '현대자동차', '컴프레서', '', '30대', '539가구', '', '하덕호', '', '갤럭시S4', '박용린', '작은 차체', '언양주유소', '', '26일', '바빈스키 반사', '마이크로소프트', '북한', '1988년', '', '', '양 CTO', '100조원', '12일', '5%', '', '김보년', '', '신성(新星)', '절편 절제술', '27일', '100%', '직업 교육', '6억500만원', '무게중심', '', '85.9%', '룬그로', '3kHz', '박재욱', '9만6800원', '', '', '산호초', '고용', '바티칸', '다음달', '지난 1월', '', '특수활동비', '밤 12시', '1969년', '22일', '', 'K2C 소총', '35%', '‘참조위험률’', '5조원', '175개 차종', 'K3', '', '상주', '황제 고종', '사민당', '80V', '', '', '류젠차오', '일본', '3092가구', '더덕 튀김', '7억달러', '9개', '1989년', '왕명', '도요타', '1997년', '새정치민주연합', '', '독일', '고려대', '틸로 헬터', '2009년', '지난해 8월', '하나은행', '찬성 31', '1.2%', '올초', '강철', '서울 용산구', '12명', '120명', '34개', '10월 16일', '조정점수', '9000만달러', '정유신', '11월2일', '', '10월', '', '3년', 'KB대우증권', '‘찰도우’', '기원전 57년', '비트코스', '투팍 아마루', '', '관세', '541m', '에티오피아', '555가구', '1290명', '아틀란5 지도', '', '', '프린스윌리엄군', '자치권', '29일', '롯데백화점', '8곳', '', '', '바쉐론콘스탄틴', '', '현대라이프', '1636년', '북한 회령시', '지연작전', '폭설', '솔레놉신', '1998년', '', '네 차례', '', '서울', '', '6.7%', '루블화', '11월 7일', '11월 7일', '‘팀 레드’', '72주', '소나골', '유비', '', '3017명', '2007년', '2.3%', '기독교', '‘윈저’', '', '지마켓', '', '조흔판', '', '33%', '2006년', '폐렴 합병증', '충남 천안시', '기상청', '뉴저지', '', '광고용 포스터', '지난해 3월', '지난해 3월', '', '5000만원', '', '대통령', '이지은', '김민준', '2006년', '', '예스24', '', '', '㈜카카오게임즈', '수원역', '새누리당', '유모차', '', '2019년', '예술의전당', '8개', '1989년', '', '‘오션팰리스’', '왕권', '149억원', '1.8V', '국민연금공단', '롯데하이마트', '', '레밍즈', '남성', '서울', '김치볶음밥', '', '84.4%', '8년', '21일', '1만4000대', '', '이집트', '', '33장', '', '크니도스', '8만여명', '‘JGJ팀’', '중앙아시아', '1963년', '희민', '새정치연합', '윤원형 일파', '', '보리스 존슨', '이승환', '', '작년 7월', '러시아 내전', '공산주의', '7447억원', '제일기획', '2015년', '24일', '서울외국어고', '‘무한도전’', '유영복', '왕(汪)씨', '퇴행성 질환', '', '이명박', '37명', '1998년', '54개', '지난해 3월', '', '감정', '68명', '동아원그룹', '신제윤', '50~60㎞', '2011년', '‘협업’', '구글', '흑사병', '신한생명', '', '대상', '‘윤쌤’', '‘국세기본법’', '한국경제신문', '', '', '', '대통령이 하야', '', '', '110명', '19.89%', '동적 완화장치', '', '강 노인', '대구', '워싱턴 DC', '', '15억원', '600만 원', '헨리 5세이', '\"바라아\"', '', '법관', '308조', '절벽', '11월 21일', '교황 지상권', '72', 'BMW', '5000만원', '르노', '1549년', '롯데백화점', '', '은의 채굴', '신한금융지주', '오스만 제국', '지난달 30일', '경남 합천군', '이메일', '4만원', '피에르 오주로', '21가지', '클디', '', '2004년', '세네갈', '500루비', '오후 4시', '화소수', '', '중국', '예거마이스터', '베트남', '11일', '6주', '대구', '', '', '224%', '벤 버냉키', '3900억원', '', '‘소풍’', '6.1%', '작년 11월', '10월 29일', '미치 매코널', '', '비학산', '', '굴착기', '2006년', '380명', '5분', '1994년', '9년', '순감자빵', '48.9%', '24일', '3개', '그레고리 맨큐', '65만원', '종이', '여포', '충남 천안', '', '이성재', '', '', '1682년', '1863년', '30%', '랠프 타우너', '', 'KKR', '게임스팟', '1089조원', '', '', '', '코로나 19', '만 39세', '', '', '패닌', '전국 대학생', '', '0시1분전', '댄 주래프스키', '체포영장', '1017억원', '유아용 변기', '', '목수', '존재론', '생물측정학파', '추첨', '', '지난 24일', '세아트', '9월', '100분의 3', '10일', '', '차가운 점액', '현대자동차그룹', '', '', '파울', '정종철', '《후한서》', '이질', '황영기', '리드 싱어', '', '', '기부', '', '5개', '', '', '', '', '', '기둥', '', '척 로빈스', '캘빈 쿨리지', '박지웅', '', '1987년', '', '살리 베리샤', '10편', 'SH공사', '80점', '4%', '8월 6일', 'CCSI', '37.1%', '45.9%', '8210만t', '30%', '프랑스', '센트럴 플라자', '22년', '', '', 'E클래스', '2011년', '긴테쓰 사양', '작년 9월', 'BS캐피탈', '26일', '고려대', '반동탁연합군', '의사', '', '팔레스타인', '박대영', '1992년', '6일', '5일', '미쓰비시중공업', '롯데건설', '쿠빌라이 칸', '64명', '2.42%', '', '', 'STX조선해양', '미국 상원', '유대인들', '유대인', '영업이익', '서초구', '구양수', '', \"'언덕'\", 'H5N8형', '8살', '기아자동차', '양당(楊黨)', '18일', '', '31일', '10일', '', '코끼리', '', '부산관광홍보관', '1998년', '‘넥시움’', '', '', '포스코', '6년', '6채', '260억 개', \"'스핑크스'\", '10% 이상', '전용 85㎡', '‘테디졸리드’', '', '김영목', '', '', '4197억원', '김준기', '11%', '현무암 화방벽', '양도소득세', '900L', '1월 21일', '1급', '이투스청솔', '53.5%', '', '신흥우', '', '160명', '5~6년', '61.1%', '', '방카슈랑스', '북인', '‘집행자’', '', '신제윤', '', '', '네 개', '', '‘데이 캠핑’', '‘링커’', '', '단식', '', '새정치민주연합', '박근혜', '유두', '제너럴모터스', '1993년', '', '3주', '삼성물산', '', '러시아', '1973년', '2010년', '', '2004년', '11월29일', '90억원', '이의구초등학교', '박윤선', '', '에세이', '금강산', '다음달 14일', '', '1000억원대', '100억원', '《로동신문》', '인하대', '서울대', '불교', '976가구', '김수현', '자신의 연금', '인구 증가', '스노우㈜', '이대희', '100명', 'SOS버튼', '3만5000원', '', '전용 앱', '건국대', '김보미', '', '', '피터 실턴', '한양대', '하나캐피탈', '지하철', '검증위원회', '', '', '19명', '', '25일', '운심리', '스위스', '44', '2003년', '', '', '300개', '《피론 어록》', '', '태하', '15.08%', '120회', '반납제도', '', '헤라', '1998년', '시체탕', '2012년', '', '지난 5월', '양정규', '', '', '3월', '', '비디비치', '김선명', '타오바오', '서울', '윈도 95', '김정은', '소독약', '', '8월', '3680만원', '에흐네', '6층', '공업경영학과', '프랜차이즈법', '배영찬', '15만8명', '', '', '이기재', '2011년', '1937년', '조영탁 한', '청년', '', '', '스위치 이더넷', '클라우드 서버', '', '200만원', '전립선암', '금융위원회', '케이스위스', '케이스위스', '의료 목적', '1987달러', '호텔면세사업부', '중국', '', '삼지애니메이션', '9개', '‘짱아’', '', '앙겔라 메르켈', '80억원', '', '1843년', '감반(甘盤)', '', '한국마사회', '국민은행', '', '', '7일 이후', '1월 6일', '3월12일', '사락사라', '프로머', '', '', '민주통합당', '6000원', '2006년', 'LG생명과학', '오상헌', '기독교', '시카고', '러시아와 중국', '25년', '오릭스', '2006년', '신의 왕국', '60억원', '적성훈장', '경상도', '철도의 채권', '1999년', '', '', '장현세', '', '전북 장수군', '국민연금기금', '', '로드 레이버', '2013년', '문재인 대통령', '4개', '', '상수원 오염', 'ID 시리즈', '동탑', '대구', '', '문화체육관광부', '', '2013', '', '', '8대', '해왕성', '에쓰오일', '일리노이주', '252명', '만 18세', '9월 21일', '밀양 농잠학교', '군종 이맘', '바이러스 감염', '대림산업', '5년', '앨허슈펠드극장', '', '국립칠곡숲체원', '‘세움터’', '16일', '182억원', '', '코멕스산업', '30일', '물적 성과', '빅토르 유셴코', '', '코스닥 시장', '요금할인선택제', '', '툴라', '구글 시스코', '와이오밍 호', '', '', '9월', '흑설탕', '5억원', '한국도자기', '아르헨티나', '2008년', '구로카와', '28', '2001년', '‘한삼인분’', '1619년', '고소득층', '', '3.2%', '', '디지털 유통', '', '유틀란트 해전', '47,746명', '13%', '알파인스키', '', '박원순', '댄스 가수', '파라과이', '1972년', '녹색', '팔', '로맨스', '1986년', '서울옥션', '29일', '', '', '', '2008년', '12월 12일', '', '', '2009년', '약 2000㎞', '버락 오바마', '마크 헨리', '생리대', '이언 샌섬', '', '26명', '트위터', '', '랑세스', '73.2점', '미국', '중장', '서울대', '', '정갑영', '후 후아펑', '', '마닐라 공항', '', '독일', '', '', '', '3477억원', '', '‘트루밸런스’', '21세기', '탄두르 오븐', '778명', '66세', '2008년', '', '6월', '', '스마트폰', '', '부산은행장', '102.12엔', '서울장신대', '성균관대', '3500개', '10년', '북베트남군', '427마디', '7일', '충북대', '', '강성', '4820억원', '에버르', '내년 상반기', '', '미국', '영어교사', '안영배', '7층', '1조원', '5월3일', '', '12월 14일', '네이버', '80%', '부평구청역', '시리아 반군', '', '‘동창생’', '‘인생 특가’', '5억원', '보신 전쟁', '', '', '국회', '', '', '일본', '27일', '보조금 차별', '화대군', '아일랜드', '우후루 케냐타', '마드리드', '교회', '', '약 30억원', '노송도', '80명', '', '오는 26일', '2차 세계대전', '', '전자책', '클레오파트르', '', '30만개', '하얀색', '72.2%', '', '김성희', '', '바지 자락', '', '워런 버핏', '1만5300원', '금태칠기', '11월 5일', '26일', '프로필', '김중수', '성장 잠재력', '2분기', '심백강', '', '브이스퀘어', '500명', '', '누에고치', '쿠보', '좀비', 'C구역', '1112년', '10월', '356ppi', '가시광선', '수소', '드라비다어 족', '주거비', '②번', '화석연료', '', '2017년', '이철수', '', '전기요금', '내년 7월', '제물포터널', '', '', '500원', '60대로', '', '시나이 반도', '', '김원준', '시장의 우상', '', '드레스덴', '', '올해 말', '금산', '윤성주', '러트렐 루프', '', '35곳', '11월 2일', '정부서울청사', '신부전증', '2007년', '고마루 산', '장기 연체자', '', '5월 10일', '기업 광고', '', '', '3.09%', '40건', '', '', '깨진 술잔', '', '오산', '파이로웨이브', '3개 시·도', '1900년', '테오도릭 대왕', '히기누스', '28%', '살인', '', '미얀마', '', '하내태수', '바깥쪽', '호랑이', '공격수', '레이나', '김일영', '미국', '716.9㎜', '세트', '국방부', '값비싼 합금', '미국 뉴욕', '이계우', '', '다음달 13일', '‘책속의한줄’', '‘캠카드’', '‘톡상담’', '', '', '소비자', '', '', '', '조지 호수', '750억원', '10%', '', '1148억원', '메디아 왕국', '미국', '9000여명', '애브비', '450억달러', '대림산업', '', '네오 아카디아', '', '11~22일', '신정호', '', '삼성전자 애플', '', '', '', '', '박미향', '‘로보케어’', '', '지난해 말', '', '', '카를 5세', '올해 1월', '', '조재호', '든 존맨', '의상대사', '', '', '뉴욕 연방은행', '15년', '지하 2층', '시종착역', '이상기온', '', '53', '3개월', '코오롱글로벌', '15대', '5천원', '', '2년', '', '5개', '', '필기시험', '민주당', '넷오일코리아', '', '', '', '고용 노동', '일본', '2013년', '3%', '14명', '정예솔 심사역', '박광명', '김대중', '22일', '300억원', '', '조현준', '9.63%', '', '3월 28일', '', '산업은행', '안음현감 곽준', '1개', '노조', '동양시멘트', '김남일', '두산중공업', '60%', '우즈베키스탄', '런던', '블록체인', '민간 투자자', '', '', '2013년', '서울 롯데호텔', '16억달러', '', '', '50㎜', '', '', '', '', '293년', '80%', '셰필드', '단자오이', '강신호', '', '1923년', '‘16층', '우마이야조', '중국 상하이', '김영준', '2006년', '', '지난 9일', '700원', '348만대로', '3만3000㎡', '', '부가가치세', '연 2%', '마리오 드라기', '', '23일', '', '', '지난 8일', '필수 지방산', '', '롯데그룹', '롯데그룹', '', '감위 분점', '개인적으로', '1945년', '3000만엔', '강남구', '820만불', '기술평가시스템', '지퍼 부분', '타흐신 야즈즈', '', '사령관', '(주)SK', '', '징역 7년형', '유기태양전지', '256TB', '적층기술', '0.02%', '1986년', \"'심리불속행'\", \"'아베노믹스'\", '', '인도 남부지방', '', '', '1조달러', '', '1504년', '시속 320㎞', '81.4%', '지난 7월', '헬리오시스', '정연성', '정연성', '1억원', '', '예수', '', '', '', '최태홍', '마이크 혼다', '푸루족', '9월27일', '23%', '와이드파크', '철도노조', '언군의 첩', '2004년', '헝디엔그룹', '3일', '13일', '카산드라', '경제청서', '', '6.66%', '수석부회장', '교육부', '롯데마트', '해양경찰청', '국제법', '주지사', '', '이승훈', '강석훈', '바닥보호공', '매일 저녁', '8명', '', '16일', '약 3년 전', '화사 대수', '클럽라운지', '6월', '13일', '남만주 지역', '기획재정부', '‘이면가격’', '', '2009년', '유한성', '인도네시아', '60억원', '예수님', '연청권', '대제 손권', '우리카드', '주양자', '미국', '김창희', '《고전통변》', '', '제롬 파월', '', '', '', '중산나라', '네이버', '6만2000톤', '2010년', '이수만', '포스코', '해변', '408곳', '갤럭시S4', '군대 해산', '베니스', '40만명', '렉싱턴호텔', '대만', '46.5%', '116개', '', '결핵', '지난해 9월', '이순우', '', '5.85%', '', '3000억원', '한국', '22일', 'SK텔레콤', '이노우에', '강학', '루신다 크리톤', '2011년', '', '‘위로 쌓는’', '봉급', '', '안드레아 기지', '물가안정', '농업노동자', '자존감', '8개월', '', 'SK텔레콤', '22석', '', '한국', '연립여당', '', '', '헬 반도', '원모 팀장', '1989년', '2002년', '‘우선협상권’', '', '취홍빈', '47.7대로', '4000대', '18곳', '‘헤이 홈’', '일본', '\"라이트스펠\"', '8개', '국민연금', '김연아', '', '콜리플라워', '2020년', '7월 31일', '', '부총재', '이화경', '', '모스크바', '2012년', '', '부산', '', '2008년', '통합진보당', '삼성전기', '1988년', '', '경북도', '일본', '', '', '', '1만5000원', '', '임개', '김유식', '', '권계면 부근', '강동구', '플랑베르주', '', '2004년', '황화구리 결정', '', '', '사회주의', '', '1857년', '문예회관', '', '', '구글', 'SC', '', '임금', '380만원', '7곳', '1만8337대', '', '미국', '셔우드 숲', '1888년', '', '2억년', '', '기업은행', '인하대', '', '두 개의', '', '2011년', '보수당', '', '신년사', '일본', '2012년', '생명보험협회장', '22.3%', '담보물의 상태', '', '인터넷', '', '26일', '', '17일', '7월', '190억달러', '2005년', '엘니뇨', '정 진제 스님', '300페타플롭', '', '5996억원', '원형의 휠', '2011년', '오툉의 리첼다', '마무드 2세', 'KB금융그룹', '건설원가', '15년', '개포주공1단지', '', '송국빈', '아지트', '4.9%', '퍼시스', '5,000원', '108억원', '사흘', '물채', '확률정보', '퍼니프로', '경복궁', '4위', '22일', '', '강대련', '지방관', '경제', '', '마곡사파', '', '수평적 관계', '', '', '4개', 'LG전자', '', '', '부르크', '비드', '이창용', '한빛미디어', '2011년', '크리슈나무르티', '', '', '화살', '시진핑', '9500억원', '', '', '', '1930년', '', '경동시장', '150만㎾급', '개신교의 자유', '1000만원', '널드 코스', '7334개', '2009년', '', '조선 중기', '', '수소와 헬륨', '', '', '17곳', '스테인리스강', '코스텔니치카', '삼화고속', '5000만원', '3441억원', '10월', '', '2009년', '에스티앤컴퍼니', '인도', '', '3900억원', '제주총영사관', '1980년', '전력·자동화', '동반성장위원회', '박성철', '일본', '국토교통성이', '85대', '', '19.1%', '최인식', '', '1515년', '중국', '국토교통부', '10월 3일', '고위 관리자', '97개', '', '궁중', '', '지엔코', '오아하카주', '5만4160대', '2009년', '코로나19', '임대주택', '15%', '택시', '전남', '6명', '1997년', '400억원', '알루미늄', '', '미국', '6월27일', '라자그리하', '', '바그라트', '티켓몬스터', '단백질', '', '실적 확인', '《엘 볼라》', '2층', '4월', '1975년', '컬럼비아', '아난 준로', '원삼국시대', '', '3월 중순', '스퀘어', '정비사업', '1982년', '', '최정우', '', '에너지 효율성', '', 'SK텔레콤', '74만여t', '달라 지역', '지난달 31일', '대런 윌슨', '‘지오송지오’', '피에몬테', '경기 평택', '4만여 호', '올림픽 기를', '', '《한중록》', '14일', '노영심 씨', '노영심', '비리 사건', '검암역', '', '2009년', 'KT빌딩', '닛산', 'LG전자', 'CJ게임즈', '660.9㎢가', '성북구', '', '', '', '정규봉', '유휴특허', '프랑스군', '민진당', '김보미', '니 기븐', '콘티넨탈', '80%', '11일', '이경태', '', '6월 8일', '9시 30분', '카드사', '2008년', '연 2%', '영국', '37세', '', '지난 11일', '아시아나항공', '키', '등록의 정정', '', '1000억원', '', '한화건설', '샬롯 필드', '경추', '211만대', '', '‘나심’', '', '2009년', '', '덴마크', '', '헝가리', '로마 가톨릭', '', '서울', '유니온페이카드', '레아', '80억달러', '문관효', '청농체', '허지행', '20여개국', '㈜제이에프티', '좌우대칭', '', '서울 여의도', '', '3일', '4년', '동메달', '‘랜슬롯’', '니코틴', '소방방재센터', '', '몸보', '319실', '제프리 가오', '4년', '미국', '12월 11일', '김창근', '27일', '간이식 기술', '수막염', '2010년', '', '1개', '임상혁', '', '수천', '트리아 터너', '3일', '금융권 종사자', '아시아', '1925년', '', '30.4%', '밀로셰비치', '', '스파이크 리', '한국사', '', '', \"'초일기'\", 'MBN', '', '', '', '1973년', '우성타이어', '5개', '이재광', '듀시)', '고영지', '8월 29일', '30%', '1884년', '1987년', '펠레 화산', '미국', '19일', '마거릿 대처', '상사병', '30명', '콜드 데이터', '', '', '몽수', '황진선', '《그대와 나》', '', '', '제일모직', '548가구', '세무서', '1867년', '', '김주하', '홋카이도', '대한항공', '1만1720원', '펩시코', '프랑스 2TV', '6개', '', '60%', '5일', '웹 2.0', '84㎡', '넥서스', '2130억원', '100주', '21회', '잡귀', '', '탈경계', '', '미국', '성북구', '5월', '목요일', '3명', '포름알데하이드', '', '', '‘성신양회’', '귀', '바비 듀에트', '피터 드파지오', '악성 댓글', '', '', '절', '에프앤가이드', '', '4113억원', '정책자문위원제', '겨울철', '', '랭스 성경', '', '', '경상남도 지역', '2010년', '5일', '', '2000원', '카르발라 지역', '', '임팩타민', '1997년', '', '김광호', '윤병구', '138%', '영국', '', \"'동시'\", '인종조사국', '원자힘현미경', '아브토바즈', '', '57개', '12개월', '금융위원회', '배액', '스마트DB', '20~40대', 'A', '세비야', '', '', '니켈 촉매', '', '스파크랩', '5000만원', '미네소타 주', '1200만원', '1991년', '9월 14일', '18일', '', '리처드 윈터스', '강수진', '1860년', '18학점', '현대종합상사', '17.5배', '애굽', '김성우', '', '26일', 'K-iDEA', '27일', '29일', '4개', '롤링 스톤스', '김상윤 매니저', '1170만달러', '', '폴 고갱이', '서울 봉래동', '50여명', '', '정경인', '15.8%', '', '', '11년', '1만9900원', '', '2009년', '계절밥상', '150여명', '500개', '5년', '', '열대의 바다', '1995년', '김서룡', '텔레비전', '박원순', '', '', '', '1천여명', '', '남측을 방문', '', '박정희', '', '450여명', '2%', '', '', '', '토도수학', '27일', '‘페르소나’', '이의철', '유대인의 집', '31일', '목욕탕', '전북 임실군', '용평리조트', '열', 'B-2', '쿠폰', '5시10분', '안나 파블로바', '정구호', '', '', '초승달', '6개월', '85분', '19.6%', '12월 3일', '', '', '190개', '3만개', '스페이스리버', '김관용', '이기문', '요안니스', '페이스북', '키치너', '', '', '17억원', '심경도 표시계', '1000만달러', '98점', '키스 알렉산더', '정부 정책', '', '잠복 경찰', '‘사업신청’', '문치미르', '', '정률제', '30~50%', '볼라벤', '20분', 'GTR', '2003년', '이인재', '챌린저스 대회', '연인관계', '', '', '10여명', '교도통신', '114㎡', '115개', '0.5%', '항공모함', '싱가포르', '정신건강의학과', '', '동천체육관', '', '\"개새끼\"', '판교', '', '고신우', '', '김관용', '이현석', '코지마 마스터', '고재호', '20대', '', '', '이주자', '바그다드', '공정거래위원회', '1944년', '', '조윤선', '베이시스트', '세일하이텍', '국회의원', '5000억원', '1301만명', '별미가', '화상회의', '아베노믹스', '', '3호선', '‘버즈런처’', 'JTBC', '824년', '4년', '실업률', '2월 13일', '6.5%', '조병옥', '순천', '‘구미호’', '0.5명', '오정근', '', '', '성시흡', '615년', '150가구', '0.33%', '브르타뉴 공국', '', '혈관', '19.7%', 'CNN', '일본', '제주', '의료용', '2004년', '1명', '', '3일', '미래부', '경남 의령군', '노희찬', '예약판매', '농협금융', '498명', '1월 11일', '32개', '', '이규광', '‘변연계’', '특정 자산', '36만', '2017년', '9월', '흔한 루트킷들', '테스트 유효성', '적십자', '', '10개국', '', '독립 공사', '20주년', '청량리', '‘스마일클럽’', '', '농업', '', '31일', '히로시', '', '세무서', '김민재', '황찬성이', '', '151명', '', '김완중', '', '입춘(立春)', '', '해직 교사', '3만원', '60년 회갑', '30일', '조돌석', '튀르크화', '', '', '키노트 연설', '', '', '열의', '5개', '비밀번호', '5~10%', '240가구', '', '', '', '1979년', '박원순', '', '', '3위', '', '여신동', '롤플레잉 게임', '에세이평가', '민섭', '', '', '이인규 지원관', '손가락', '', '', '2탄', '7인치', '', '13일', '32만 원', '', '', 'NADPH', '', '항히스타민제', '오정근', '2017', '탑골공원', '19.6㎏·m', '오후 5시', '4명', '', '', '6.1008', '국가방위군', '2009년', '조 수석', '선우예권', '', '', '울산', '쿤드리도', '2014년', '마이크로소프트', '2년', '100만명', 'MBC', '서울시 공무원', '무사트', '2013년', '100만원', '', '5년', '', '', '애플', '일본', '프랑스', '<투란도트>', '노동자계급', '6000원', '', '', '트렁크', '주나라', '', '스위스', '', '90%', '', '', '일등바위', '모리 류헤이', '4만건', '조영탁', '', '', '순치제', '공상타작놀이', '', '', '송도컨벤시아', '', '김태현', '', '17일', '동반위', '구루 나나크', '이소연', '닥나무', '3호선', '신혜성', '23~25일', '300만 원', '한화건설', '미 해병대', '', '56.2%', '', '내년 12월', '레이퀸 빨대컵', '', '프레스티지', '라파엘클리닉', '청나라의 다롄', '1만5000유', '대만', '임봉주', '‘연애세포’', '1730년대', '홍라희', '5000원', '19일', '드림파마', '천봉삼', 'CYP효소', '두 달', '절', '이해진', '', '에넥스', '외국인', '2003년', '생산 일자', '기업', '‘리니지’', '2009년', '부근 대밭골', '캐딜락 CT6', '조양호', '', '스위스', '', '투명 빨래판', '1138가구', '다음달 4일', '프리메이슨', '', '50㎏', '', '카자흐스탄', '10퍼센트', '', '바고아스', '맨해튼', '', '', '', '요우이백화점', '', '신성전투', '다케다', '이윤수', '6경기', '31일', '브라질', '', '2814억원', '', '2005년', '0.2%포인트', '1625년', '2017년', '2011년', '중국 분마그룹', '114명', '1996년', '마이크로소프트', '나치의 인종법', '러시아', '제8조', '가계부채 관리', '', '20일', '용산구', '1982년', '', '스폰지밥', '', '2014', '지아만', '부통령', '남중국해', '', '', '카를 마르크스', '1999년', '현생인류', '1만원', '35t', '101곳', '2004년', '경기 포천시', '미쓰비시중공업', '', '박종훈', '안티고노스', '중국', '2004년', '우운검', '', '한국도자기', '', '2007년', '지난 5일', '현대로템', '코나EV', '자동차 산업', '1938년', '봄부터 초여름', '기원전 54년', '「티탄즈」', '오는 4분기', '', '', '', '금융위원회', '안종범', '', '', '', '10월', '사케츠 항구', '', '제리 양', '패트릭 자라', '나치당', '기초노령연금', '9월', '', '4300개', '오후 6시', '페터 비에리', '장안리', '박종철', '수열', '5~10초', '홍콩', '호주', '‘22’', '현대엠코', '기병', '', '20.2%', '480엔', '', '중앙 헌병단', '', '10일', '비밀 투표', '', '거짓말', '‘∧’ 모양', '1940년', '', '설계수명', '9.2%', '', '3개', '', '‘외환상담반’', '', '21일', '1999년', '257표', '11월 2일', '22일', '그리스 아테네', '', '인구 미달', '', '건설사', '누진세', '46.39%', '보름달 근처', '', '', '헤이케', '500만원', '뒤로 재주넘기', '', '6배', '록스타', '4', 'ESC', '', '스웨덴', '', '', '나무 상자', '', '8일', '', '허갑범', '대한변협', '신제윤', '', '', '8월 17일', '', '최진균 부회장', '', '', '', '65살', '', '', '', '부산', '9월', '저작권법', '하체', '올해 3월', '중국', '3시간', '악성코드', '바른', '가을', '', '신한은행', '금천구', '', '네 명의', '‘브리오니’', '공수부대', '', '‘윌리봇’', '반냥전', '지난 22일', 'CJ', '16세', '서울', '', '', '', '일본', '뉴욕 맨해튼', '5.7인치', '대우건설', '', '시베리아', '한 허부', '', '21일', '', '샤오미', '일주일', '16%', '', '현대자동차', '3곳', '백유진', '', '', '파란색', '이마', '-12%', '‘부르심제로’', '삼광글라스', '지난달', '', '', '현대모비스', '베니스의 해변', '3952명', '페이펄', '피터 틸', '1864년', '지하 소극장', '도미노 피자', '', '음독자살', '아이폰5s', '', '9억원', '야누스캐피털', '포스코건설', '1만1250원', '특별 리워드', '웨스트우드', '', '법원', '《희망 수업》', '1945년', '미트리다테스', '온도', '', '코 점막', '봉건귀족', '40g', '46개', '박근혜 대통령', '8595건', '1억원', '', '', '', '신한금융투자', '', '기생파리', '', '22일', '2014년', '26㎡', 'SD300', '107억원', '흑색육', '', '모치즈키 시장', '21일', '아이', '14.5%', '유연탄', '2011년', '돌다리', '플레기아스', '김종필', '판교테크노밸리', '유로존', '', '마술적인 선율', '회진임씨', '아리스톤', '24일', '한종호', '페이스북', '금조3부', '', '정우', '', '프랑스', '2004년', '지난해 11월', '캡슐머신', '파인디지털', '130억유로', '0.2%포인트', '병인박해', '', '', '44만명', '600 플로린', '야시로 에이타', '타우리엘', 'EFD시스템', '', '2011년', '', '', '', '', '우유 생산비', '1991년', '', '30만명', '현대건설', '경추척수증', '올해 2월', '민주사회당', '', '2개', '', '내재적 보상', '', '', '실버*', '70점', '200만엔', '', '', '사흘', '벨기에']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame({'predicted': pred})\n",
        "pred_df"
      ],
      "metadata": {
        "id": "9hI0RSBk5isn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sub = pd.concat([sub,pred_df], axis=1)\n",
        "new_sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QTNGCT9y54z1",
        "outputId": "d56c8c0c-fa58-4440-b864-38097de1c8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Id         Predicted predicted\n",
              "0     d14cb73158624cf094c546d856fd3c80  뉴 740Li 25주년 에디션          \n",
              "1     906631384e91493ebe1c7f34aea6f241         독일 뒤셀도르프로          \n",
              "2     35e61dcb479643448a2cb7d326ae50a6              링크트인      링크트인\n",
              "3     075e761b370040cb9041eecd39afc27c              링크트인      링크트인\n",
              "4     e67ed38f3dd944be94d5b4c53731f334              마드리드      마드리드\n",
              "...                                ...               ...       ...\n",
              "4003  05fcb8054dc44dab8683579c2cf5e465             200만엔     200만엔\n",
              "4004  cc7f826b66724ce9b39e3a974ca15661          중동 건설 현장          \n",
              "4005  3282034aa41e4fab980851ffd4a868dd         아시아~유럽 노선          \n",
              "4006  0a73550b36df4baf82ac2f98619d22e7                사흘        사흘\n",
              "4007  dfe6ef25f84f461e89e54d370e4521d5               벨기에       벨기에\n",
              "\n",
              "[4008 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1efd33e-9ada-4e9d-8a09-439a027ea2fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d14cb73158624cf094c546d856fd3c80</td>\n",
              "      <td>뉴 740Li 25주년 에디션</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>906631384e91493ebe1c7f34aea6f241</td>\n",
              "      <td>독일 뒤셀도르프로</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35e61dcb479643448a2cb7d326ae50a6</td>\n",
              "      <td>링크트인</td>\n",
              "      <td>링크트인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>075e761b370040cb9041eecd39afc27c</td>\n",
              "      <td>링크트인</td>\n",
              "      <td>링크트인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e67ed38f3dd944be94d5b4c53731f334</td>\n",
              "      <td>마드리드</td>\n",
              "      <td>마드리드</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>05fcb8054dc44dab8683579c2cf5e465</td>\n",
              "      <td>200만엔</td>\n",
              "      <td>200만엔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>cc7f826b66724ce9b39e3a974ca15661</td>\n",
              "      <td>중동 건설 현장</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4005</th>\n",
              "      <td>3282034aa41e4fab980851ffd4a868dd</td>\n",
              "      <td>아시아~유럽 노선</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4006</th>\n",
              "      <td>0a73550b36df4baf82ac2f98619d22e7</td>\n",
              "      <td>사흘</td>\n",
              "      <td>사흘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4007</th>\n",
              "      <td>dfe6ef25f84f461e89e54d370e4521d5</td>\n",
              "      <td>벨기에</td>\n",
              "      <td>벨기에</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4008 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1efd33e-9ada-4e9d-8a09-439a027ea2fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1efd33e-9ada-4e9d-8a09-439a027ea2fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1efd33e-9ada-4e9d-8a09-439a027ea2fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = new_sub.drop(new_sub.columns[1], axis=1)\n",
        "final.to_csv('/content/drive/MyDrive/Groom_8th_project2/finall.csv', sep=',' ,na_rep='')\n",
        "\n",
        "final"
      ],
      "metadata": {
        "id": "TG89xbIv54qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = []\n",
        "\n",
        "for i in range(4008):\n",
        "  submission.append([final['Id'][i], final['predicted'][i]])\n",
        "submission"
      ],
      "metadata": {
        "id": "XjcR71tJ64Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "os.makedirs('out', exist_ok=True)\n",
        "with open('out/baseline.csv', 'w') as fd:\n",
        "    writer = csv.writer(fd)\n",
        "    writer.writerow(['Id', 'Predicted'])\n",
        "    writer.writerows(submission)"
      ],
      "metadata": {
        "id": "pCjLV_W5-32R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "456c66659c6247f6a06499a0b5cf2c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "614d5563229b43189707a55c932d5a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72a1c8b379154b4995d9ffdc087a70f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76309ea9985a412884f079510582906c",
            "placeholder": "​",
            "style": "IPY_MODEL_882b5a5c14db4217b21d17d4a6bc4664",
            "value": " 543/28740 [01:37&lt;1:21:07,  5.79it/s]"
          }
        },
        "76309ea9985a412884f079510582906c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a2610466d440478c5e1dfdb3a4225e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882b5a5c14db4217b21d17d4a6bc4664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa904bba27514e5d853cfc21e122e8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a2610466d440478c5e1dfdb3a4225e",
            "max": 28740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_614d5563229b43189707a55c932d5a49",
            "value": 543
          }
        },
        "b6417c9e5f6e43ec807ccd1c11e594c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5390134ea304ef981ee2b22b1552c87",
              "IPY_MODEL_aa904bba27514e5d853cfc21e122e8e0",
              "IPY_MODEL_72a1c8b379154b4995d9ffdc087a70f8"
            ],
            "layout": "IPY_MODEL_456c66659c6247f6a06499a0b5cf2c2f"
          }
        },
        "bb8f5063e76a42db88844d5021dc69cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5390134ea304ef981ee2b22b1552c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f60e2ce41f10493d91be93c26e20e449",
            "placeholder": "​",
            "style": "IPY_MODEL_bb8f5063e76a42db88844d5021dc69cf",
            "value": "Train - Loss: 6.237:   2%"
          }
        },
        "f60e2ce41f10493d91be93c26e20e449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
